# Two Pointer

- two pointer
  - 배열에서 원래 이중 for문으로 O(N<sup>2</sup>)에 처리되는 작업을 2개 포인터의 움직임으로 O(N)에 해결하는 알고리즘
    - 완전 탐색으로 풀면 시간 초과가 나는 문제에 적용하면 풀리는 경우가 많다.
  - 종류
    - 앞에서 시작하는 포인터와 끝에서 시작하는 포인터가 만나는 형식
    - 동일한 지점에서 시작하여 빠른 포인터가 느린 포인터 보다 앞서가는 방식
  - 유사한 알고리즘으로 슬라이딩 윈도우가 있다.






# 에라스토테네스의 체

- 에라스토테네스의 체

  - 소수(prime number)를 판별하는데 사용하는 알고리즘이다.
    - 고대 그리스의 수학자 에라스토테네스가 발견하였다.
    - 체 처럼 소수가 아닌 수 들을 걸러낸다.
  - 알고리즘
    - 2부터 소수를 구하고자 하는 구간의 모든 수를 나열한다.
    - 나열한 수를 앞에서부터 탐색해 나간다.
    - 첫 수인 2는 소수이므로 소수라는 표시를 한다.
    - 나열 된 숫자들에서 2의 배수인 것들은 모두 소수가 아니라는 표시를 한다.
    - 3은 표시가 되어 있지 않고, 소수이므로 소수라는 표시를 한다.
    - 나열 된 숫자들에서 3의 배수인 것들은 모두 소수가 아니라는 표시를 한다.
    - 4는 소수가 아니라는 표시가 되어 있으므로 넘어간다.
    - 5는 표시가 되어 있지 않고, 소수이므로 소수라는 표시를 한다.
    - 나열 된 숫자들에서 5의 배수인 것들은 모두 소수가 아니라는 표시를 한다.
    - 이를 모든 수에 대해 반복한다.
  - 구현

  ```python
  def prime_list(n):
      # 에라토스테네스의 체 초기화: n개 요소에 True 설정(소수로 간주)
      sieve = [True] * n
  
      # n의 최대 약수가 sqrt(n) 이하이므로 i=sqrt(n)까지 검사
      m = int(n ** 0.5)
      for i in range(2, m + 1):
          if sieve[i] == True:           # i가 소수인 경우
              for j in range(i+i, n, i): # i이후 i의 배수들을 False 판정
                  sieve[j] = False
  
      # 소수 목록 산출
      return [i for i in range(2, n) if sieve[i] == True]
  ```

  - 주의사항

    > [참고](https://nahwasa.com/entry/%EC%97%90%EB%9D%BC%ED%86%A0%EC%8A%A4%ED%85%8C%EB%84%A4%EC%8A%A4%EC%9D%98-%EC%B2%B4-%ED%98%B9%EC%9D%80-%EC%86%8C%EC%88%98%ED%8C%90%EC%A0%95-%EC%8B%9C-%EC%A0%9C%EA%B3%B1%EA%B7%BC-%EA%B9%8C%EC%A7%80%EB%A7%8C-%ED%99%95%EC%9D%B8%ED%95%98%EB%A9%B4-%EB%90%98%EB%8A%94-%EC%9D%B4%EC%9C%A0)

    - n까지의 소수 판별시에 n의 제곱근까지만 확인하면 된다(위 코드에서도 `n ** 0.5`까지만 확인했다).
    - n은 자연수 a, b에 대해 `n = a * b`라고 표현할 수 있다.
    - 또 n의 제곱근 m에 대해 `n = m * m`라고 표현할 수 있다.
    - 따라서, `a * b = m * m`이라 할 수 있다.
    - 이 때, a, b는 자연수여야하므로, a, b가 자연수임을 만족하는 경우는 아래의 세 가지 경우 뿐이다.
    - `a=m & b=m`, `a<m & b>m`, `a>m & b<m`
    - 즉, `min(a, b)<=m`이라고 할 수 있다.
    - N의 약수에 해당하는 a와 b 중 하나는 무조건 m 이하이므로, m까지만 조사하면 n이 소수인지 알 수 있게 된다.



# 연결 리스트

- Floyd's cycle finding algorithm(Hare-Tortoise algorithm)

  - 단일 연결 리스트에 cycle이 존재하는지를 판별하는 알고리즘이다.

    - 거치는 모든 노드를 저장 할 필요 없이, 포인터 두 개만 있으면 되므로 공간복잡도 O(1)에 해결이 가능하다.
    - 시간 복잡도는 O(n)이다.

  - 방식

    - 한 칸씩 전진하는 포인터(slow pointer, tortoise)와 두 칸씩 전진하는 포인터(fast pointer, hare)를 동일한 시작점에서 출발시킨다.
    - 만일 연결 리스트에 순환이 존재할 경우 두 포인터는 반드시 만나게 된다.
    - 만약 순환이 존재하지 않을 경우 fast pointer가 연결리스트의 끝에 도달하게 된다.

  - 이를 사용하여 cycle의 시작점을 찾을 수도 있다.

    - 한 칸씩 전진하는 포인터(slow pointer, tortoise)와 두 칸씩 전진하는 포인터(fast pointer, hare)를 동일한 시작점에서 출발시킨다.
    - 두 포인터가 만나게 되면 둘 중 한 포인터를 시작점으로 돌려보낸다.
    - 이제 두 포인터 모두 한 칸씩 전진시키면, 두 포인터가 만나는 지점이 순환의 시작점이다.

  - cycle의 시작점을 찾는 원리

    - y는 두 포인터의 시작점부터 순환의 시작점까지의 거리이다.
    - z는 순환의 시작점부터 두 포인터가 만나는 지점까지의 거리이다.
    - l는 순환의 길이이다.
    - f는 fast pointer가 순환을 돈 횟수, s는 slow pointer가 순환을 돈 횟수이다.
    - $x_n$은 연결 리스트의 n번째 노드이다.
    - $x_i$는 두 포인터가 만나는 노드이다.
    - $x_j$는 순환 내부에 있는 노드이며, 순환 내부에 있는 노드 $x_j$에 대해 아래의 공식이 성립한다. 즉, node가 순환 내에 존재한다면 몇 순환을 몇 번 돌아도 같은 지점에 도착하게 된다.

    $$
    x_{j+kl} = x_j\ \ (j \geλ\ and \ k\ge0)
    $$

    

    - 이 때 두 포인터가 만날 때 까지 slow pointer가 이동한 거리 i는 아래와 같다.

    $$
    i = y+(s*l)+z
    $$

    - fast pointer는 slow pointer의 두 배씩 이동하므로, 두 포인터가 만날 때 까지 fast pointer가 이동한 거리 2i는 아래와 같다.

    $$
    2i = y+(f*l)+z
    $$

    - 2i에서 i를 빼면 아래와 같다.

    $$
    i = (f-s)l
    $$

    - 이제 첫 번째 식에서 j에 y를 대입한다.
    - y는 연결 리스트의 시작점부터 순환의 시작점까지의 거리이므로, $x_y$가 가리키는 node는 순환이 시작되는 node이고, 따라서 순환 내부에 있는 node라 할 수 있다.
    - 그 다음 k값에는 fast pointer가 순환을 돈 횟수에서 slow pointer가 순환을 돈 횟수를 뺀 f-s를 대입하면 식은 아래와 같다.

    $$
    x_{y+(f-s)l} = x_y
    $$

    - 여기서 우리는 `(f-s)l`의 값이 i라는 것을 알고 있으므로, 식은 아래와 같이 변경될 수 있다.

    $$
    x_{y+i}=x_y
    $$

    - 즉 두 포인터가 만나는 지점($x_i$)에서 y만큼 이동하면 사이클이 시작되는 지점($x_{y+i}$)로 돌아갈 수 있다.

  - Runner technique
    - 두 개의 pointer를 동일한 시작점에서 서로 다른 속도로 출발시킨다는 아이디어로 다양한 문제 해결이 가능하다.
    - 예를 들어 cycle이 없는 연결 리스트에서 fast pointer가 끝에 도달하면, slow list는 중간 지점에 도달하게 되는데, 이를 사용하여 회문 판별등을 할 수 있다.








# Deque와 우선순위 큐

- Deque(Double-Ended Queue, 데크, 덱)
  - 양쪽 끝에서 삽입과 삭제가 모두 가능한 자료형.
    - 일반적으로 이중 연결 리스트를 사용하여 구현한다.
  - Python의 경우 `collections` 모듈에서 `deque`로 지원한다.
  - 시간복잡도
    - 양쪽 끝에서의 삽입은 O(1).
    - 양쪽 끝에서의 삭제는 O(1).
    - 양쪽 끝의 원소 확인은 O(1).



- 우선순위 큐
  - 추출시 우선순위가 가장 높은 요소를 추출하는 자료형
    - 스택은 가장 나중에 들어간 요소가 먼저 추출되고, 큐는 가장 처음 들어간 요소가 먼저 추출된다.
    - 그러나 우선순위 큐는 특정 조건에따라 우선순위가 가장 높은 요소가 추출된다.
  - 시간복잡도(당연히 구현에 따라 달라지며, 아래는 힙을 사용했을 경우의 시간복잡도이다).
    - 원소의 추가는 O(lg N).
    - 우선순위가 가장 높은 요소의 확인은 O(1).
    - 우선순위가 가장 높은 요소의 추출은 O(lg N)





# 연결리스트

- Array와 list

  > 자료구조로서의 array, list와 프로그래밍 언어에서의 array, list를 분리해서 생각해야한다.
  >
  > 예를 들어 C의 영향으로 array는 길이를 변경할 수 없다고 생각하지만, 자료구조로서의 array는 단순히 메모리상에 원소를 연속하여 배치한 구조로, 길이를 변경하지 못할 이유가 없다.

  - array
    - 일반적으로 배열이라 번역되는 array는 메모리상에 원소를 연속하게 배치한 자료구조이다.
    - 메모리상에 연속적으로 배치하므로, index를 사용하여 k번째 원소를 상수 시간에 찾는 것이 가능하다.
    - 추가적으로 소모되는 메모리의 양(overhead)가 거의 없다.
    - 메모리상에 연속된 구간에 할당해야하므로 할당에 제약이 존재한다(C는 이러한 제약을 극복하기 위해 array의 길이를 변경하지 못하게 설계됐다).
    - Cache hit rate가 높다.
  - array의 시간복잡도
    - index를 알고 있을 경우 해당 index에 해당하는 값에 접근하는 것과 변경하는 것의 시간복잡도는 O(1)이다.
    - 임의의 위치에 자료를 추가하거나 삭제하는 연산의 시간복잡도는 O(n)이다. 추가, 삭제 이후 element들을 한 칸씩 당기거나 밀어야 하기 때문이다.
    - array의 마지막에 원소를 추가, 삭제하는 경우의 시간복잡도는 O(1)이다.

  - list
    - 메모리상에 원소를 불연속적으로 배치한 자료구조이다.
    - 메모리상에 원소를 불연속적으로 배치하므로 index를 통한 접근이 불가능하다.
    - 배열과 유사한 역할을 하지만 차이가 있다면 빈 element를 허용하지 않는다는 것이다.
    - 빈틈없는 데이터의 적재가 가능해 낭비되는 메모리가 거의 없다.
    - 배열과 마찬가지로 원소들 사이의 순서가 존재하며, 또한 배열과 마찬가지로 중복을 허용한다.
    - 연속되어 배치되지 않으므로 Cache hit rate가 낮다.



- 연결리스트
  - 데이터 요소의 선형 집합으로, 데이터의 순서가 물리적인 순서대로 저장되지 않는다.
    - 컴퓨터과학에서 배열과 함께 가장 기본이 되는 대표적인 선형 자료구조 중 하나로 다양한 추상 자료형(Abstract Data Type, ADT) 구현의 기반이 된다.
    - 동적으로 새로운 노드를 삽입하거나 삭제하기가 간편하며, 연결 구조를 통해 물리 메모리를 연속적으로 사용하지 않아도 되기 때문에 관리도 쉽다.
  - 랜드 연구소에서 근무하던 앨런 뉴얼이 동료들과 함께 만든 언어인 IPL의 기본 자료구조로 처음 사용됐다.
  - 연결 리스트의 성질
    - 배열과는 달리 특정 인덱스에 접근하기 위해서는 전체를 순서대로 읽어야하므로 상수 시간에 접근할 수 없다.
    - 메모리상에 연속되어 배치되지 않으므로 cache hit rate가 낮다.
    - 각 원소가 다음 원소, 혹은 이전과 다음 원소의 주소값을 가지고 있어야하므로, 추가적인 메모리 공간(overhead)이 요구된다. 
    - 예를들어 32비트 컴퓨터면 주소값이 32비트(=4바이트) 단위이니 4N 바이트가 추가로 필요하고, 64비트 컴퓨터라면 주소값이 64비트(=8바이트) 단위이니 8N 바이트가 추가로 필요하게 된다. 즉 N에 비례하는 만큼의 메모리를 추가로 쓰게 된다.'
  - 시간 복잡도
    - 탐색과 변경에는 O(n)이 소요된다.
    - 반면, 시작 또는 끝 지점에 아이템을 추가, 삭제, 추출하는 작업은 상수 시간에 가능하다.
    - 시작 또는 끝 지점이 아닌 임의의 공간에 추가와 삭제를 하는 경우 추가 또는 삭제 할 곳의 주소를 알고 있을 때에만 O(1)이다.
    - 예를 들어 1->34->17->22와 같은 연결 리스트가 있을 때, 세 번째 원소 뒤에 61을 추가하려 한다면 이는 상수 시간 내에는 불가능하다.
    - 세 번째 원소가 어디인지를 찾는데 시간이 소요되기 때문이다.
    - 단, 주소를 알고 있을 경우에는 단순히 추가하려는 원소 앞의 원소가 가리키는 주소를 추가한 원소의 주소로 바꾸고, 추가한 원소가 가리키는 주소를 뒤의 원소로 바꿔주기만 하면 된다.



- 연결 리스트의 종류
  - 단일 연결 리스트(Singly linked list)
    - 각 원소가 다음 원소의 주소를 가지고 있는 연결 리스트
  - 이중 연결 리스트(Doubly linked list)
    - 각 원소가 자신의 다음 원소의 주소와 이전 원소의 주소를 가지고 있는 연결 리스트
    - 이전 원소의 정보를 알 수 있다는 장점이 있지만, 단일 연결 리스트에 비해 추가적인 메모리가 필요하다는 단점이 있다.
  - 원형 연결 리스트(Circular linked list)
    - 처음 원소와 마지막 원소가 연결되어 있는 연결 리스트
    - 단일 연결 리스트이면서 원형 연결 리스트일 수도, 이중 연결 리스트이면서 원형 연결 리스트일 수도 있다.





# Hash

> https://blog.encrypted.gg/1009

- 해시 함수
  - 임의 크기 데이터를 고정 크기 값으로 매핑하는 데 사용할 수 있는 함수를 말한다.
    - 고정 크기 값이 아닌 가변 크기 값으로 매핑하는 해시 함수도 있기는 하다.
    - 해시 함수를 사용하는 것을 해싱이라 하는데, 해싱은 정보를 가능한 빠르게 저장하고 검색하기 위해 사용하는 기법 중 하나다.
  - 해시
    - 해시 함수가 반환한 값을 hash value, hash code, digest, hash 등으로 부른다.
    - 이 값들은 일반적으로 hash table이라 부르는 고정 크기의 table의 index로 사용된다.
    - hash table을 indexing하기 위해서 hash function을 사용하는 것을 hashing 혹은 scatter storage addressing이라 부른다.
  - 버킷과 슬롯
    - 버킷과 슬롯은 table의 행과 열이라고 보면 된다.
    - 버킷이 해시값으로 이루어진 index이며, 하나의 버킷은 여러 개의 slot을 가질 수 있다.
  - 성능 좋은 해시함수들은 아래와 같은 특징을 가진다.
    - 해시 함수 값 출돌의 최소화
    - 쉽고 빠른 연산
    - 해시 테이블 전체에 해시 값이 균일하게 분포
    - 사용할 키의 모든 정보를 이용하여 해싱
    - 해시 테이블 사용 효율이 높을 것



- 해시 충돌

  - 해시 함수가 서로 다른 두 개의 입력값에 대해 동일한 출력값을 내는 상황을 의미한다.
    - 해시 함수를 이용하는 자료구조나 알고리즘의 효율성을 떨어뜨리므로, 해시 충돌이 자주 발생하지 않도록 구성되어야한다.
  - 예시
    - 인구 1만인 A국은 주민등록 번호와 주민을 mapping 시키려한다.
    - 주민번호는 0000000000부터 시작해서 9999999999까지 있을 수 있으며,  총 10자리라는 것 외에는 특별한 규칙이 없다.
    - 추가, 조회, 수정, 삭제가 가장 빠른 방법은 10의 10제곱 크기의 배열을 만들고 주민번호를 인덱스로 하여 관리하는 것이다.
    - 이 경우 추가, 조회, 삭제, 수정이 모두 index로 접근 가능하므로 O(1)에 해결이 가능하다.
    - 예를 들어 3548126771이라는 주민등록 번호에 김철수를 등록한다고 한다면 배열에서 3548126771번 인덱스에 해당하는 값을 김철수로 입력하기만 하면 된다.
    - 그러나 문제는 1만명의 정보를 저장하기 위해서 10의 10제곱 크기(100억)의 배열을 만드는 것이 너무 비효율적이라는 것이다.
    - 따라서 index기반 접근이라는 장점은 그대로 가져가면서, 메모리도 효율적으로 사용하기 위해 hash값을 사용하여 5자리로 축약한 주민 번호(5자리로 축약할 경우 필요한 배열의 길이는 100000)를 index로 사용하기로 한다.
    - 주민등록 번호를 hash 값으로 변환하는 hash 함수는 주민등록 번호의 앞 5자리만 떼는 방식으로 한다.
    - 이제 또 다른 문제가 발생한다.
    - 우리가 정의한 hash 함수는 앞의 5자리만을 떼므로, 앞의 5자리가 같으면 hash 함수는 모두 같은 값을 반환한다.
    - 예컨데 0000000000 ~ 0000099999는 모두 같은 hash값을 반환한다.
    - 이와 같은 상황을 hash 충돌이라 한다.
  - 해시 충돌의 발생을 막을 수 있는 방법은 없는가
    - 해시 함수의 목적 자체가 함수의 입력으로 주어지는 정의역의 공간이 너무 커서 이걸 바로 배열의 index로 활용할 수 없으니 범위를 줄이고자 하는데 있다.
    - 즉, 정의역의 범위에 비해 치역의 범위가 작으므로, 비둘기집 원리에 의해 해시 충돌이 발생하는 것 자체를 막을 수 있는 방법은 없다.

  - 비둘기집 원리(서랍 원리)
    - n개의 요소를 m개의 컨테이너에 넣을 때, n>m이라면 적어도 하나의 컨테이너에는 반드시 2개 이상의 요소가 들어가게 된다는 원리이다.
    - 1834년 독일의 수학자 페터 디리클레(Peter Dirichlet)가 만들었다.

  - 생일 문제(Birthday Problem)
    - 생일의 수는 윤년이 아니라고 가정하면 365개이다.
    - 비둘기집 원리를 생각해보면 366명 이상이 모여야 해시 충돌이 일어날 것 같지만, 실제로는 그렇지 않다.
    - 비둘기집 원리는 366명 이상이면 **반드시** 해시 충돌이 발생함을 보여줄 뿐이다.
    - 같은 생일이 존재할 확률은 23명만 모여도 50%를 넘고, 57명이 모이면 99%를 넘어선다.
    - 즉, 해시 충돌은 생각보다 쉽게 일어날 수 있다.




- 로드 팩터(Load Factor, 부하계수, 적재율)
  - 로드 팩터는 해시 테이블에 저장된 데이터 개수 n을 해시 테이블 크기 k로 나눈 것(n/k)이다.
    - 로드 팩터가 증가할수록 해시 충돌 확률이 높아지므로, 해시 테이블의 성능은 감소하게 된다.
  - 로드 팩터 비율에 따라 해시 함수를 재작성해야할지, 해시 테이블의 크기를 조정해야 할지를 결정한다.
  - Java 10에서는 해시맵의 디폴트 로드 팩터를 0.75로 설정했다.
    - 시간과 공간 비용의 절충안이었다.





# 해시 충돌 발생시 회피 기법

> https://blog.encrypted.gg/1009

- 해시 충돌 발생시 회피하는 방법
  - 해시 충돌을 회피하는 것을 불가능하다.
  - 따라서 해시 충돌 차제를 회피하는 방법이 아니라 해시 충돌이 발생했을 때 이를 우회하는 방법이 필요하다.



- Chaining

  - 연결 리스트로 한 버킷 내의 데이터들을 연결하는 방식이다.

    - 각 버킷마다 연결 리스트를 하나씩 만든다.
    - 그리고 삽입이 발생하면 해당 인덱스에 해당하는 연결 리스트의 head에 해시 전 값과 함께 mapping할 값을 추가한다.

  - 예시

    - 예를 들어 기존 방식이 아래 표와 같았다면(일반적으로 해시값을 행으로 그리지만 편의를 위해 열로 그린다)

      | 00000  | 00001 | 00002  | ...  | 99999  |
      | ------ | ----- | ------ | ---- | ------ |
      | 김철수 |       | 이영희 |      | 최길동 |

    - 이제는 hash 전 값과 함께 저정한다.

      | 00000              | 00001 | 00002              |      | 99999              |
      | ------------------ | ----- | ------------------ | ---- | ------------------ |
      | head               |       | head               |      | head               |
      | 0000001789, 김철수 |       | 0000206487, 이영희 |      | 9999912173, 최길동 |

    - 그리고 동일한 값이 추가될 경우 연결 리스트의 head에 추가한다.

      | 00000              | 00001 | 00002              | ...  | 99999              |
      | ------------------ | ----- | ------------------ | ---- | ------------------ |
      | head               |       | head               |      | head               |
      | 0000001789, 김철수 |       | 0000298754, 박영구 |      | 9999912173, 최길동 |
      |                    |       | 0000206487, 이영희 |      |                    |

    - 만일 주민번호가 0000206487인 사람을 해시 테이블에서 제거하려 한다면 먼저 00002 버킷으로 이동한 뒤, 연결 리스트의 첫 번째 값부터 탐색을 시작하여, 0000206487를 찾을 때 까지 탐색을 계속한 후 찾으면 삭제한다.

    - 수정, 조회 역시 마찬가지다.

  - 시간복잡도

    - 삽입의 경우 연결 리스트의 head에 추가하므로 O(1)이다.
    - 최악의 경우 모든 데이터가 하나의 버킷에 전부 들어가 있을 수 있으므로 삭제, 탐색의 시간복잡도는 O(n)이다.



- Open Addressing

  - 해시 충돌이 일어나면 다른 버킷에 데이터를 삽입한다.

    - Chaining과 마찬가지로 해시 전 값과 mapping할 data를 함께 저장한다.

  - 삽입 예시

    - 0000100000를 삽입한다.

      | 00000 | 00001              | 00002 | 00003 | 00004 | ...  | 99999 |
      | ----- | ------------------ | ----- | ----- | ----- | ---- | ----- |
      |       | 0000100000, 김철수 |       |       |       |      |       |

    - 0000100001을 삽입하려 하는데 00001은 이미 차있으므로, 한 칸 뒤인 00002에 삽입한다.

      | 00000 | 00001              | 00002              | 00003 | 00004 | ...  | 99999 |
      | ----- | ------------------ | ------------------ | ----- | ----- | ---- | ----- |
      |       | 0000100000, 김철수 | 0000100001, 박철수 |       |       |      |       |

    - 0000200000을 삽입하려는데 00002는 이미 차있으므로, 한 칸 뒤인 00003에 삽입한다.

      | 00000 | 00001              | 00002              | 00003             | 00004 | ...  | 99999 |
      | ----- | ------------------ | ------------------ | ----------------- | ----- | ---- | ----- |
      |       | 0000100000, 김철수 | 0000100001, 박철수 | 000020000, 이철수 |       |      |       |

    - 0000100002를 삽입하려는데, 00001은 이미 차 있으므로, 한 칸 뒤로 간다. 그런데 00002, 00003모두 차 있으므로 00004에 저장한다.

      | 00000 | 00001              | 00002              | 00003             | 00004              | ...  | 99999 |
      | ----- | ------------------ | ------------------ | ----------------- | ------------------ | ---- | ----- |
      |       | 0000100000, 김철수 | 0000100001, 박철수 | 000020000, 이철수 | 0000100002, 최철수 |      |       |

  - 조회 예시

    - 삽입 예시의 최종 hash table에서 0000100002가 누구의 주민등록번호인지를 찾으려 한다.
    - 우선 00001 이 가리키는 값을 확인해보는데, 0000100002와 다르다.
    - 뒤로 밀린 것일 수 있으므로, 00002, 00003을 거치며 다음 칸을 쭉 순회하며 확인하다 00004에 저장된 값을 찾아낸다.
    - 만일 0000100003을 찾으려 한다면 역시 마찬가지로 00001부터 쭉 순회하며 찾다가 00005가 비어있음을 확인함과 동시에 0000100003이 존재하지 않음이 확실시 되고 탐색이 종료된다.

  - 삭제 예시

    - 0000100001을 지우려 한다.

    - 위에서 살펴본 방식으로 조회하여 00002에 저장되었다는 것을 찾을 수 있고, 이 값을 삭제한다.

      | 00000 | 00001              | 00002 | 00003             | 00004              | ...  | 99999 |
      | ----- | ------------------ | ----- | ----------------- | ------------------ | ---- | ----- |
      |       | 0000100000, 김철수 |       | 000020000, 이철수 | 0000100002, 최철수 |      |       |

    - 이 때, 000020000을 찾으려 한다고 가정해보자.

    - 우선 00002를 볼 것인데, 00002가 가리키는 값은 이전에 삭제되었으므로, 빈 칸인 상태이다.

    - 따라서 00003에 0000200000가 존재함에도 불구하고, 없다고 판단하고 탐색이 종료된다.

    - 이와 같은 문제를 해결하기 위해서 삭제한 후 삭제한 칸에 dummy data를 두던가 하는 방식으로 원래 값이 있었지만 지금은 삭제되었다는 표시를 해줘야한다.

    - 탐색시에는 삭제 표시가 있다면 다음 값을 계속 탐색하고, 삽입 시에는 삭제 표시가 있다면 삭제 표시를 지우고 값을 삽입하는 식으로 사용해야한다.

  - Probing

    - 충돌 발생시 충돌한 값을 어디에 넣을 것인지에 대한 정책이다.
    - Linear probing은 충돌 발생시 바로 다음 칸에 넣는 방식으로, 구현이 간단하고, 인접한 공간에 저장하므로 cache hit rate이 높다는 장점이 있지만, clustering 된다는 단점이 있다.
    - Quadratic probing은 충돌이 발생하면 1, 4, 9, ... 칸씩 제곱만큼 이동시켜 저장하는 방식으로 clustering이 linear probing보다 덜 하다는 장점이 있지만, cache hit rate이 낮다는 단점이 있다.
    - Double hashing은 해시 함수를 하나 더 둬서 충돌이 발생했을 때 어디에 저장할지를 추가 해시 함수의 값으로 계산하는 방식으로, clustering이 보다 덜 하지만, cache hit rate이 낮다는 단점이 있다.



- 두 방식의 비교

  > http://egloos.zum.com/sweeper/v/925740

  - Chaining의 장점
    - 상대적으로 간단한 방식으로 구현이 가능하다.
    - Clustering의 영향을 거의 받지 않으므로 해시 함수 구현시 충돌의 최소화만 살펴보면 된다. 반면에 open-addressing은 clustering의 영향을 받으므로 해시 함수를 구현할 때 clustering도 최소화시켜야한다.
    - Hash table이 채워져도(load factor가 증가해도) 성능 저하가 linear하게 발생한다. 반면에 open-addressing 방식은 load factor가 일정 값을 넘어가기 시작하면 성능저하가 급격히 증가하기 시작한다.
  - Open-Addressing의 장점
    - Chaining과 달리 추가적인 작업 공간(연결 리스트)를 필요로 하지 않는다.
  - 결론
    - Open-Addressing의 경우 data의 크기가 작고 예측 가능할 때 사용하는 것이 좋다.
    - Chaining은 높은 load factor가 예상되거나, data의 크기가 크거나 가변적일 때 사용하는 것이 좋다.

