# 목차

- [알고리즘](#알고리즘)
- [복잡도](#복잡도)
- [진수](#진수)
- [실수의 표현](#실수의-표현)
- [비트](#비트)
- [파이썬의 숫자 자료형](#파이썬의-숫자-자료형)
- [문자표현](#문자표현)
- [그래프](#)
  - [서로소 집합](#서로소-집합)
  - [최소 신장 트리(MST,Minimum Spanning Tree)](#최소-신장-트리)
  - [최단경로](#최단경로)
- [Stack과 Queue](#Stack과-Queue)
  - [Stack](#Stack)
  - [Queue](#Queue)
- [Linked List](#Linked-list)
- [Tree](#Tree)
- [반복과 재귀](#반복과-재귀)
- [순열과 조합, 부분집합](#순열과-조합,-부분집합)
  - [순열](#순열)
  - [부분집합](#부분집합)
  - [조합](#조합)
- [탐욕(greedy) 알고리즘](#탐욕-알고리즘)
- [Divide and Conquer(분할정복)](#Divide-and-Conquer)
- [Backtracking(백트래킹)](#Backtracking)
- [문제 풀면서 알게 된 것들](#문제-풀면서-알게-된-것들)
- [팁](#팁)



# 알고리즘

- 알고리즘: 유한한 단계를 통해 문제를 해결하기 위한 절차나 방법



- 알고리즘의 조건
  - 입력: 알고리즘 수행에 필요한 자료가 외부에서 입력으로 제공
  - 출력: 알고리즘 수행 후 하나 이상의 결과를 출력
  - 명확성: 수행할 작업의 내용과 순서를 나타내는 알고리즘 명령어들은 명확하게 정의되어야 한다.
  - 유한성: 알고리즘은 수행 뒤에 반드시 종료
  - 효과성: 알고리즘의 모든 명령어들은 기본적이며 실행 가능해야 함.



- 문제 해결 과정

  - 문제의 모델링
    - 문제를 읽고 이해
    - 문제를 익숙한 용어로 재정의
  - 문제를 해결할 알고리즘 찾기

  - 알고리즘의 검증
    - 충분한 성능과 적절한 메모리 사용에 대한 검증
  - 프로그램으로 구현
  - 어떻게 풀었는지 돌아보고, 개선할 방법은 없는지 고민

  

- 문제 해결 전략
  - 비슷한 문제를 풀어본 적 있는지 고민
  - 단순한 방법에서 시작할 수 있을지 고민
  - 문제를 단순화 할 수 있을지 고민
  - 그림, 수식 등으로 표현 할 수 있을지 고민
  - 문제를 분해할 수 있을지 고민
  - 뒤에서부터 생각해서 문제를 풀 수 있을지 고민



- 좋은 알고리즘
  - 정확성: 얼마나 정확하게 동작하는가
  - 작업량: 얼마나 적은 연산으로 원하는 결과를 얻어내는가
  - 메모리 사용량: 얼마나 적은 메모리를 사용하는가
  - 단순성: 얼마나 단순한가
  - 최적성: 더 이상 개선할 여지없이 최적화되었는가





# 복잡도

- 알고리즘의 효율성은 공간적 효율성과 시간적 효율성으로 나눈다.
  - 공간적 효율성: 얼마나 많은 메모리 공간을 요하는가
  - 시간적 효율성: 얼마나 많은 시간을 요하는가
  - 복잡도는 효율성을 뒤집어 표현한 것이다.



- 공간 복잡도
  - 알고리즘을 프로그램으로 실행하여 완료하기까지 필요한 총 저장 공간의 양



- 시간적 복잡도 분석

  - 하드웨어 환경에 따라 처리 시간이 달라진다.
  - 소프트웨어 환경에 따라 처리 시간이 달라진다(프로그래밍 언어의 종류, 운영체제 등).

  - 이러한 환경적 차이로 인해 분석이 어렵다.



- 복잡도의 점근적 표기
  - 시간, 공간 복잡도는 입력 크기에 대한 함수로 표기하는데, 이 함수는 주로 여러 개의 항을 가지는 다항식.
  - 이를 단순한 함수로 표현하기 위해 점근적 표기(Asymptotic Notation)을 사용
  - 입력 크기 n이 무한대로 커질 때의 복잡도를 간단히 표현하기 위해 사용하는 표기법이다.
  - 종류
    - O(Big-Oh)표기
    - Ω(Big-Omega)표기
    - θ(Big-Theta)표기



- O(Big-Oh)표기
  - 복잡도의 점근적 상한을 나타낸다(최대 이정도 시간이 걸린다).
  - T(n)은 실제 실행 시간, 복잡도를 의미
  - T(n)<=c*f(n)이 되는 상수 c,n<sub>0</sub>가 존재할 때(c, n<sub>0</sub>는 n의 값에 독립적)만 O(Big-Oh)표기 사용 가능
    - c는 임의의 상수, n<sub>0</sub>는 초기값
  - T(n) = O(f(n))이라고 한다.
  - 예시
    -  T(n)=2n<sup>2</sup>-7n+4
    - T(n)의 복잡도 표기는 n<sup>2</sup>
    - T(n)<=c*f(n)을 예시에 적용해보면 2n<sup>2</sup>-7n+4<=3n<sup>2</sup>(c=3, f(n)=n<sup>2</sup>)
    - n<sup>2</sup>-7n+4<=0, 이를 근의공식으로 풀어보면 n >= 1.xxx/2가 된다. 따라서 n은 1일 수 있다.
    - 결국 c = 3(임의의 상수),  n<sub>0 </sub>= 1일 때 T(n)<=c*f(n)가 성립하므로 O(Big-Oh)표기법으로 표기 가능
    - T(n)=O(n<sup>2</sup>)으로 표현하고 이는 n이 증가함에 따라 2n<sup>2</sup>-7n+4이 cn<sup>2</sup>보다 클 수 없다는 의미이다.



- Ω(Big-Omega)표기
  - 복잡도의 점근적 하한을 나타낸다(최소한 이만한 시간은 걸린다).
  - T(n) >= c*f(n)이 되는 상수 c,n<sub>0</sub>가 존재할 때(c, n<sub>0</sub>는 n의 값에 독립적)만 Ω(Big-Omega)표기 사용 가능
  - T(n) = Ω(f(n))이라고 한다.



- θ(Big-Theta)표기
  - T(n) = O(f(n)) 이고 T(n) = Ω(f(n)) 일때 T(n) = θ(f(n))이 성립한다.
  - n<sub>0</sub>보다 크거나 같은 모든 n에 대해서 c<sub>1</sub>*f(n)<=T(n)<=c<sub>2</sub>*f(n)이 되는 상수 c<sub>1</sub>, c<sub>2</sub>, n<sub>0</sub>가 존재할 때만 표기 가능
  - T(n) = θ(f(n))이라고 한다.





# 진수

- 추천문제: swea_1240, swea_1242
- 파이썬에서 10진수 이외의 진수는 모두 아래와 같이 수 앞에 문자를 붙여서 표현한다.
  - 2진수: `0b`
  - 8진수: `0o`
  - 16진수:`0x`



- 10진수를 타 진수로 변환하는 방법
  - 원하는 타 진법의 수로 나눈 뒤 나머지를 거꾸로 읽는다.



- 2진수, 8진수, 16진수간 변환
  - 2진법을 8진법으로 바꿀 때는 3자리씩 묶으면 되고, 역으로 수행할 때는 3자리씩 나열하면 된다.
  - 2진법을 16진법으로 바꿀 때는 4자리씩 묶으면 되고, 역으로 수행할 때는 4자리씩 나열하면 된다.



- 16진 표기법

  - 16진수는 2진수로 저장된다.

  - 10진수를 16진수로 변환하는 과정, 16진수를 10진수로 변환하는 과정은 2진수와 동일하다.

  - 16진수 한 자리는 2진수 4자리로 표현한다.

    - 7DF는 2진수로 다음과 같이 표현한다.

    - 7은 2진수로 0111, D(13)는 2진수로 1101, F(15)는 2진수로 1111
    - 011111011111 

  - 16진수는 0~9, A~F를 사용해 표현한다.

    - 0~9는 10진수의 0~9와 동일, A~F는 10진수의 10~15와 동일
    - 즉 0~F를 사용해 0~15를 표현한다.
    - 16진수임에도 15까지만 표현하는 이유는 16으로 나눈 가장 큰 나머지가 15이기 때문이다.

  - 16진수로 변환 예시

    - 2015를 16진수로 표현하면
    - 2015/16=125...15
    - 125/16=7...13
    - 7, 13, 15을 16진수로 표현하면 7,D,F가 된다.
    - 결국 10진수 2015의 16진수 표기는 0x7DF이다.

  - 10진수로 변환 예시
    - 16진수 0x7DF를 다시 10진수로 변환하면 16\*\*2\*7+16\*\*1\*13+16\*\*0\*15=2015

    

- 엔디안(Endianness)

  - 16진수의 1비트는 2진수 4비트로 표현된다.

  - 그렇다면 0x01020304는 00000001/00000010/00000011/00000100이 되야 하겠지만 결과는 00000100/00000011/00000010/00000001로 거꾸로 나온다.

  - 이런 결과가 나오는 이유는 엔디안 때문이다.

  - 엔디안: 컴퓨터 메모리와 같은 1차원 공간에 여러 개의 연속된 대상을 배열하는 방법을 의미

  - 주의: 속도 향상을 위해 바이트 단위와 워드 단위를 변환하여 연산 할 때 올바로 이해하지 않으면 오류를 발생시킬 수 있다.

    - 위에서 말하는 워드란 컴퓨터가 한번에 처리하는 단위이다.
    - ex. 64bit 운영체제에서 64bit가 워드를 의미하는 것이다.
    - 1byte=8bit

  - 종류

    - 단위: 0x1234라는 데이터가 있을 때 1은 16의 3승, 2는 16의 2승, 3은 16의 1승, 4는 16의 0승을 곱해서 10진수로 변환한다. 이때 지수가 더 큰 1,2가 큰 단위, 3,4가 작은 단위가 된다.
    - 빅엔디안: 보통 큰 단위가 앞에 나온다. 네트워크의 처리 방식
      - 빅 엔디안에서는 0x1234를 12 34로 저장한다.
    - 리틀 엔디안: 보통 작은 단위가 앞에 나온다. 대다수 데스크탑 컴퓨터의 처리 방식
      - 리틀 엔디안에서는 0x1234를 34 12로 저장한다.

  - 즉 위에서 결과거 거꾸로 출력된 이유는 리틀엔디안으로 처리가 되었기 때문이다.

  - 엔디안 확인 코드

    ```python
    #1.비트연산을 통한 확인
    n=0x00111111
    #n을 2진수로 표현하면 00000000/00010001/00010001/00010001
    
    if n&0xff:    #f는 15, ff는 2진수로 11111111
        print('little endian')
    else:
        print('big endian')
        
    #만일 리틀 엔디안으로 처리가 되었다면 00010001/00010001/00010001/00000000가 되어 
    #00010001 & 11111111의 값은 0이 아닐 것이므로 'little endian'이 출력,
    #만일 빅 엔디안으로 처리가 되었다면 00000000/00010001/00010001/00010001가 되어
    #00000000 & 11111111의 값은 0일 것이므로 'big endian'이 출력
    
    
    #2.파이썬 시스템 라이브러리를 통해 확인 
    import sys
    if sys.byteorder == 'little':
        print('little endian platform')
    else:
        print('big endian platform')
        
    #확인 필요
    print(0b00000000000100010001000100010001&0b11111111) #big
    print(0x00111111&0b11111111)
    print(0b00010001000100010001000100000000&0b11111111) #little
    print(0x00111111==0b00000000000100010001000100010001) #big
    print(0x00111111==0b00010001000100010001000100000000) #little
    
    out
    17
    17
    0
    True
    False
    ```

  - 엔디안 변환 코드

    ```python
    def change_endian(n):
        p = []
        for i in range(0,4):
            p.append((n>>(24-i*8))&0xff)  
            #24인 이유는 0x01020304가 2진수로 총 32비트 이기 때문이다. 
        return p
    
    def change_endian2(n):
        return (n<<24 & 0xff000000) | (n<<8 & 0xff0000) | (n>>8 & 0xff00) | (n>>24 & 0xff)
    ```



- 컴퓨터에서 음의 정수 표현 방법
  - 컴퓨터의 정수 표현은 `부호비트|값비트`로 표현하고 부호비트는 양수일 경우 0, 음수일 경우 1이 된다.

  - 보수: 보충을 해주는 수를 의미한다. 이를테면 1에 대한 10의 보수는 9, 4에 대한 15의 보수는 11의 개념

  - 1의 보수: 부호와 절대값으로 표현된 값을 부호 비트를 제외 한 나머지 비트들을 0은 1로, 1은 0으로 변환
    - 0에 대한 1의 보수는 1, 1에 대한 1의 보수는 0
    - 따라서 0은 1로, 1은 0으로 변환(사실상 비트의 반전)
    - 예를 들어 6은 2진수로 표현 하면 110(값비트, 정확히는 양수이므로 0110)이다. 
    - 여기에 부호비트인 1(음수)를 표시하면 1110이 된다.
    - 1의 보수 방법을 사용하여 음수로 표시하면 1001(부호비트는 변환에서 제외)이 된다.
    
  - 2의 보수: 1의 보수  방법으로 표현된 값의 최하위 비트에 1을 더한다.
    
    -  1의 보수 방법으로 표현된 100<u>1</u>의 최하위 비트(밑줄)에 1을 더하면 1002가 된다.
    -  2진수이므로 다음 자리로 넘기면 1010이 된다.
    
  - 즉, 크게 `부호비트|값비트`표현, 1의 보수 표현, 2의 보수표현의 3가지 방법이 있지만 대부분 2의 보수 방법을 사용

  - 0의 표현

    | 2진수 | 부호비트\|값비트 | 1의 보수  | 2의 보수 |
    | ----- | ---------------- | --------- | -------- |
    | 000   | 0000,1000        | 0000,1111 | 0000     |

    

  - 정수표현을 그냥 `부호비트|값비트`로 해도 되는데 굳이 보수로 표현하는 이유

    - 예를 들어 3-3을 한다고 하면, 3-3은 3+(-3)과 같으므로, 3은 0011, -3은  보수로 표현하지 않고 `부호비트|값비트`로 표현해서 계산 할 경우  1011이 된다. 둘을 더하면 1110이 되어 0이 아닌 -6이 되게 된다.
    - 1의 보수로 동일한 계산을 할 경우 3은 그대로 0011, -3은 1100이 되어 둘을 더하면 1111이 된다. 이는 0을 1의 보수로 표현한 것과 동일하다. 그러나 1의 보수로 표현한 0은 +0과 -0이 생길 수 밖에 없어서 계산이 정확하지 않고 후술할 문제(캐리의 처리)도 있어서 잘 사용하지 않는다.
    - 2의 보수로 동일한 계산을 할 경우 3은 그대로 0011, -3은 1101이 되어 둘을 계산하면 10000이 되는데 2의 보수는 계산 결과 나온 맨 앞의 1(캐리, 자리 올림)은 버린다. 따라서 0000이 되고 0을 2의 보수로 표현한 것과 동일한 값을 얻게 된다.
    - 만일 1의 보수로 계산했을 때 위의 경우와 동일하게 계산 결과 맨 앞에 1이 나오는 경우가 생긴다면 그 1을 떼고 마지막 비트에 1을 더해줘야 계산이 맞게 된다.
      - 4-3을 할 경우 4는 4비트로 0100, -3은 1100인데 둘을 더하면 10000이 된다. 이 때 2의 보수는 동일한 상황에서 1을 떼면 끝이었으나 1의 보수는 1(캐리)을 뗀 후 마지막 비트에 1을 더해서 0001이 되야 계산이 맞게 된다.
      - 동일한 계산을 2의 보수로 해보면 4는 0100, -3은 2의 보수로 1101으로 둘을 더하면 10001이 되고 캐리를 떼면 0001로 추가적인 처리 없이도 맞는 값이 나오게 된다.



# 실수의 표현

- 소수점 이하 자리를 표현하는 방법

  - 123.456이라는 10진수로 표현한 실수가 있다고 할 때 이는 아래와 같이 풀어쓸 수 있다.

    - 10<sup>2</sup>*1+10\*2+3+10<sup>-1</sup>\*4+10<sup>-2</sup>\*5+10<sup>-3</sup>\*6

  - 마찬가지로 101.101이라는 2진수로 표현한 실수가 있다고 할 때 아래와 같이 풀어쓸 수 있다.

    - 2<sup>2</sup>\*1+2<sup>1</sup>\*0+2<sup>0</sup>\*1+2<sup>-1</sup>*1+2<sup>-2</sup>\*0+2<sup>-3</sup>\*1

      

- 컴퓨터의 실수 표현

  - 부동소수점(floating-point) 표기법을 사용
    - 움직이지 않는 소수점이라는 의미가 아닌 떠다니듯이 움직이는 소수점이라는 의미이다.
  - 부동소수점과 대비되는 개념으로 고정소수점(fixed-point)이 존재
  - 고정소수점과 부동소수점의 차이
    - 고정소수점은 일반적인 표시방법대로 정수부와 실수부를 나눠서 표시
      - 1001.0011에서 1001은 정수부, 0011은 실수부
    - 부동소수점은 소수점의 위치를 왼쪽의 가장 유효한 숫자 다음으로 옮기고 밑수의 지수승으로 표현
      - 1001.0011에서 왼쪽의 가장 유효한 숫자 다음으로 소수점을 옮기면 1.0010011이 된다. 여기서 밑수의 지수숭을 곱하면 1.0010011*2<sup>3</sup>이 된다.
      - 만일 0.0010110을 부동소수점으로 표시한다면, 왼쪽의 가장 유효한 숫자 다음으로 소수점을 옮기면 1.0110이 되고 밑수의 지수승을 곱하면 1.0110*2<sup>-3</sup>이 된다.
    - 즉, 부동소수점은 지수승으로 원래 소수점의 위치를 나타내준다.

  



- 단정도 실수(32비트로 표현, 일반적으로 float 타입이라고 불림)

  - 부호1비트|지수8비트|가수23비트

  - 지수부: 실제 소수점의 위치를 지수 승으로 표현한 것

  - 가수부: 실수의 유효 자릿수들을 부호화된 고정 소수점으로 표현한 것

    - 가수부에 표현할 수 있는 수가 많아질 수록 수를 더욱 정밀하게 표현 가능

  - 지수부에 0~2<sup>8</sup>-1(256개)만큼 표현 가능

  - 가수 부분 만드는 방법(1001.0011을 예로)

    - 정수부의 첫 번째 자리가 1이 되도록 오른쪽으로 시프트(1.0010011)
    - 소수점 이하를 (0을 추가해서)23비트로 만든다(1.00100110000000000000000)
    - 소수점 이하만을 가수 부분에 저장(00100110000000000000000)
    - 지수 부분은 시프트 한 자릿수 만큼 증가 또는 감소(1.0010011*2<sup>3</sup>)

  - 지수부에는 0~255까지 나타낼 수 있지만 음수도 나타내야 하므로 익세스(excess)표현법을 사용

    - 지수부의 값을 반으로 나누어 그 값을 0으로 간주하고 음수지수와 양수지수를 표현
    - 0~255의 중간을 0으로 간주 -127~128의 값을 가진다.
    - -127은 2진수로 00000000, 10진수로 0을 나타내고, 128은 2진수로 11111111, 10진수로 255를 나타낸다. 0은 2진수로 01111111, 10진수로 127을 나타낸다.

  - 결국 1001.0011은 단정도 실수로 표현하면 다음과 같다.

    > 0|10000010|00100110000000000000000

    - 맨 앞의 0은 부호비트, 뒤의 10000010은 익세스 표현법으로 나타낸 3의 2진수(10진수로는 130)로 지수부, 00100110000000000000000는 허수부

    

- 배정도 실수(64비트로 표현, 일반적으로 double타입이라고 불림)

  - 부호1비트|지수11비트|가수52비트
  - 지수부에 2<sup>11</sup>-1만큼 표현 가능
  - 파이썬은 64비트로 처리 함에도 float이라고 표현함



- 컴퓨터는 실수를 근사적으로 표현한다.
  - 이진법으로 표현할 수 없는 형태의 실수는 근사값으로 저장되는데 이 때 작은 오차가 생긴다.
  - 실수 자료형의 유효 자릿수
    - 32비트 실수형(십진수 기준):6, 즉 소수점 6자리까지는 유효하나 그 아래는 근사값
    - 64비트 실수형(십진수 기준):15, 즉 소수점 15자리까지는 유효하나 그 아래는 근사값



# 비트

- 부분집합 관련 배경지식

  - 집합의 원소가 n개일 때, 공집합을 포함하는 부분집합의 수는 2<sup>n</sup>개이다.
  - 이는 각 원소를 부분집합에 포함시키거나 포함시키지 않는 2가지 경우를 모두 원소에 적용한 경우의 수와 같다.




- 작은 값의 10진수를 2진수로 빠르게 변환하는 방법은 해당 값이 어떤 2의 n승들을 더해서 구성되는지 알면 된다. 예를 들어 10은 2의 3승인 8과 2의 1승인 1로 구성되므로 1010과 같이 쓸 수 있고 6은 2의 2승인 4와 2의 1승인 1로 구성되므로 110과 같이 쓸 수 있다. 



- 비트 연산자

  - 종류

    | 연산자 | 의미               | 예시                                     |
    | ------ | ------------------ | ---------------------------------------- |
    | \|     | or연산             | 두 비트 값이 하나라도 1이면 1, 아니면0   |
    | &      | and연산            | 두 비트값이 하나라도 0이면 0, 아니면1    |
    | ^      | xor연산            | 두 비트값이 같으면 0, 다르면 1           |
    | !      | not연산            | 1은 0으로 0은 1로                        |
    | <<     | 왼쪽 쉬프트 연산   | 모든 비트 값을 왼쪽으로 한 자리씩 이동   |
    | >>     | 오른쪽 쉬프트 연산 | 모든 비트 값을 오른쪽으로 한 자리씩 이동 |

  - 예시

    ```python
    print(13&9)
    
    out
    9
    
    #13,9의 &연산 결과가 9가 나오는 이유는 다음과 같다.
    #13은 2진수로 1101, 9는 2진수로 1001이다. 따라서 두 2진수를 비교해보면
    # 1101
    # 1001
    # ----
    # 1001
    # 위와 같은 결과가 나오게 된다.
    ```

  

  - 비트연산자 `^`를 2번 하면 처음 값을 반환한다.

    ```python
  #비트연산자 ^의 결과값은 두 비트의 값이 다를 때만 1이 된다.
    a = 0b1100
    b = 0b1001
    a^=b    # 1번
    #1100
    #1001
    #0101
    print(bin(a))
    a^=b    # 2번
    #0101
    #1001
    #1100
    print(bin(a)) 
    
    
    
    out
    0b101
    0b1100  #처음 값으로
    ```

    

  - 바이너리 카운팅

    - a<<n은 a*2<sup>n</sup>과 같다.
  - 1<<n은 2<sup>n</sup>과 같다.  a<<1은 a에 2를 곱하는 것과 같다. a>>1은 a에 2를 나눈는 것과 같다.
    - 따라서 부분집합을 구할 때도 많이 사용한다.
  
    ```python
    arr = [3,6,7,1,5,4]
    n = len(arr)          #n : 원소의 개수
    for i in range(1<<n):  #1<<n: 부분 집합의 개수(64)
        #i는 0~63까지의 값을 가진다. 2진수로는 000000~111111(10진수로 63)까지의 값을 가진다.
        for j in range(n): #원소의 수만큼 비트를 비교함
            if i & (1<<j):  #i의 j번째 비트가 0이 아니면 j번째 원소 출력
                print(arr[j],end=", ")
        print()
     
    #원리
    #n=6이므로 000000부터 111111까지 6자리 2진수를 가지게 된다.
    #즉, 2**5,2**4,2**3,2**2,2**1,2**0의 2진수가 만들어지게 된다.
    #n=6이므로 arr의 인덱스도 0~5까지 존재하게 된다.
    #그러므로 2의 제곱과 arr의 인데스가 0~5로 일치하므로 제곱에 인덱스를 대응시킬 수 있게 된다.
    #만일 0,2,4번 인덱스에 해당하는 값으로 이루어진 부분집합 [3,7,5]가 있다면
    #2**0, 2**2, 2**4의 비트값이 1이 되는 것이므로 2진수로는 010101이된다.
    
    #즉 정리하자면 000000~111111까지의 모든 2진수를 전부 탐색하면서 각 2진수의 비트를 리스트의 인덱스에 대응시키는 방식이다.
    #좀 더 작은 리스트로 예를 들어 보면
    brr = [1,2,3]
    n = len(brr)
    result = []
    for i in range(1<<n):
        temp = []
        for j in range(n):
            if i & (1<<j):
                temp.append(brr[j])
        result.append(temp)
    print(result)
    
    out
    [[], [1], [2], [1, 2], [3], [1, 3], [2, 3], [1, 2, 3]]
    
    
    #000~111까지의 2진수를 모두 나열하면 다음과 같다
    #000,001,010,100,011,110,101,111
    #이를 각 인덱스에 대응시키면 
    #[],[1],[2],[3],[1,2],[2,3],[1,3],[1,2,3]이와 같이 된다.
    #위 코드에서 i 가 6인 경우를 예로 들면 6은 2진수로 110이므로
    #j = 0일때 110의 첫 번째 비트값은 0이므로 brr[0]은 temp에 담기지 않는다.
    #j = 1일때 110의 두 번째 비트값은 1이므로 brr[1]은 temp에 담긴다.
    #j = 2일때 110의 세 번째 비트값은 1이므로 brr[2]는 temp에 담긴다.
    #결국 [2,3]이라는 부분집합이 나오게 된다.
    ```

    

    - 2를 곱하거나 나누는 코드를 작성해야 할때 *연산자나 /연산자를 사용하는 것 보다,  >>나 <<연산자를 사용하는 것이 훨씬 실행 속도가 빠르다.
  
    ```python
    a = 10
    print(a<<1)
    print(a>>1)
    
    out 
    20
    5
    #위와 같은 결과가 나오는 이유
    #10을 2진수로 변환하면 1010이다. 이 때 <<1을 해주면
    #10100이 되고 이를 10진수로 변환하면 20이 된다.
    #결국 x<<n은 x에 2**n을 곱한 것과 같은 결과가 나오게 된다(x*2**n).
    #반대로 10을 2진수로 변환한 1010에 >>1을 해주면
    #101이 되고 이를 10진수로 변환하면 5가 된다.
    #결국 x>>n은 x에 2**n을 나눈 것과 같은 결과가 나오게 된다(x/2**n).
    ```

  - 비트마스크 

    - &는 합집합 연산자로 i&(1<<j)와 같이 쓰면 i의  j번째 비트가 1인이 아닌지를 알 수 있다.
  
    ```python
    #10은 10진수로 1010이다. 0이 나오면 비트가0, 다른 숫자가 나오면 비트가1인 것이다.
    print(10&(1<<3))
    print(10&(1<<2))
    print(10&(1<<1))
    print(10&(1<<0))
      
    out
    8
    0
    2
  0
    ```

    

  - 또한 2진수 표현을 통해 홀짝 판단이 가능하다.
  
  - 2\*\*0은 1인데 2\*\*0의 비트값이 1이면 홀수, 0이면 짝수가 된다.
    - 홀짝 판단을 할때 보통 2로 나눠서 나머지가 있는지를 보는 방식을 쓰는데 그 방식보다 아래 방식이 훨씬 빠르게 수행된다.
  
    ```python
    if 6&1:    
        print('홀수')
    else:
        print('짝수')
    
    if 5&1:    
        print('홀수')
    else:
        print('짝수')
    
    out
    짝수
    홀수
    #6은 2진수로 110이고 1은 2진수로 1이다.
    #이를 다르게 표현하면 6은 110이고 1은 001이라고 할수 있다 110과 001은 겹치는 것이 하나도 없다.
    #110
    #001
    #따라서 6은 짝수이다.
    #반면에 5는 2진수로 101인데 101과 001은 마지막 1이 겹친다.
    #따라서 5는 홀수이다.
    ```





# 파이썬의 숫자 자료형

- 타 언어에서는 정수로 표현 될 수 있는 범위가 정해져 있으나 파이썬은 범위에 제한이 없다(최대값이 정의되어 있지 않다).
- C, Java의 경우 float과 double 형이 있지만 파이썬의 경우는 C, Java의 double에 해당되는 실수형만 존재한다.
- 최대로 표현할 수 있는 범위는 1.8*10<sup>308</sup>이고 그 이상은 inf(-inf)로 표현한다.
- 최소로 표현할 수 있는 범위는 1.8*10<sup>-308</sup>이고 무한소는 0으로 표현한다.

- 실수의 오차
  - 실수의 계산은 아래와 같이 정확한 값이 나오지 않는다.
  - 다만 일반적인 상황에서는 무시해도 될 정도이므로 비교 연산(== 등)등을 사용하거나, 매우 작은 값의 계산을 할 때가 아니라면 그냥 사용해도 된다.

```python
print(0.1+0.2)
print(0.1+0.2==0.3)
print("{:.55f}".format(0.1))


out
0.30000000000000004
False
0.1000000000000000055511151231257827021181583404541015625
```

- 복소수형이 존재
  - 실수부(.real)와 허수부(.imag)로 나뉘며 실수부와 허수부는 각각 실수형으로 저장된다.
  - 허수부 뒤에는 숫자 뒤에 j또는 J를 붙여 허수부임을 표시한다.






# 문자표현

- 해싱: 키를 통해 그 키값에 해당하는 밸류를 찾는 것을 해싱이라 부른다. 딕셔너리도 이에 해당한다.



- 컴퓨터의 문자 표현

  - 영어가 대소문자 합쳐서 모두 52자이므로 6비트(2**6=64)면 모두 표현할 수 있다.

  - 초기에는 지역마다 표현 방식이 모두 달랐으나 1967년 미국에서 ASCII(American Standard Code for Information Interchange)라는 문자 인코딩 표준이 제정됨.

  - ASCII

    - 7비트 인코딩으로 128문자를 표현한다. 128문자는 33개의 출력 불가능한 제어 문자들과 공백을 포함한 95개의 출력 가능한 문자들로 이루어져 있다.

    - 일일이 대응하는 값을 외울 필요는 없지만 몇 가지 규칙을 알고 있으면 편하다

      -숫자가 대문자보다 작은 코드에 배정되어 있으며 대문자는 소문자보다 작은 코드에 배정되어 있다.

      -또한 0~9, A~Z, a~z는 각각 코드 값이 1씩 증가해 나간다.

    - 확장 아스키는 표준 문자 이외의 악센트 문자, 도형문자, 특수문자, 특수기호 등 부가적인 문자 128가지를 추가할 수 있게 하는 부호이다.

      - 기존의 아스키 코드에 1비트를 추거하여 8비트를 사용(256개)

      - 표준화된 것은 아니고 개발자가 할당하고 싶은 문자를 할당할 수 있는 것이다. 따라서 다른 사람과의 공유가 어렵다.

  - 유니코드

    - 인터넷이 전 세계로 발전하면서 국가 간에 코드 체계가 다른 문제가 발생하였고 다국어 처리를 위해 또 다시 표준을 만들었는데 이를 유니코드라 한다.

    - 여러 체계가 존재한다.

      -utf-8(웹에서 주로 사용), uff-16(윈도우와 자바에서 사용), utf32(리눅스에서 사용) 등이 있다.



- 파이썬의 문자열 처리
  - 다른 언어와 달리 char 타입이 없다, char는 다른 언어에서 한 문자를 표현하기 위한 것이나 파이썬은 한 문자도 문자열에 넣으면 된다. 예를 들어 a라는 하나의 문자를 처리하기 위해서 다른 언어에서는 char 타입을 사용해야 하지만 파이썬은 그냥 'a'와 같이 해주면 된다.
  - 문자열은 요소값을 변경 할 수 없다(immutable).



- 패턴 매칭: 주어진 패턴과 동일한 패턴을 찾는 문제

  - 일반적으로 주어진 패턴을 P 또는 p로 정의하고 그 길이를 M또는 m으로 정의하며 패턴의 인덱스를 j로 정의한다. 또한 패턴을 찾을 텍스트를 T또는t로 정의하고 그 길이를 N또는 n으로 정의하며 텍스트의 인덱스를 i로 정의한다. 

  - 내장함수가 존재한다(.find()).

    ```python
    P = "asd"
    M = len(P)
    T = "dgrgrloskmdoasdlgrpr"
    N = len(T)
    
    idx=T.find(P)  #해당 패턴이 시작하는 위치를 리턴해준다. 없을 경우 -1리턴
    print(idx, T[idx:idx+M])
    
    out
    12 asd
    ```

  - 고지식한 알고리즘: 주어진 패턴과 본문을 일일이 비교하여 찾는 것, 시간복잡도는 O(MN)

    ```python
    P = "asd"
    M = len(P)
    T = "dgrgrloskmdoasdlgrpr"
    N = len(T)
    
    #while문ver
    i = 0
    j = 0
    while i<N:
        if T[i]==P[j]:
            i+=1
            j+=1
            if j==M:
                print(i-j)  #패턴이 시작되는 인덱스를 출력
                j=0 #일치하는 패턴이 또 있을 수 있으므로 다시 j를 0으로 초기화
        else:
            i=i-j+1
            j=0
        
      
    #for문ver(주로 while로 작성하긴 한다)
    for i in range(N-M+1):
        for j in range(M):
            if P[i]!=T[i+j]:
                break
            else:
                print(i)
                i+=m #시작위치부터 m까지는 찾는 의미가 없으므로 +m해준다.
    ```

  - KMP알고리즘(이 알고리즘을 발견한 3명의 이름 첫자를 딴 것이다)

    - 불일치가 발생한 텍스트 스트링의 앞 부분에 어떤 문자가 있는지를 알고 있으므로, 불일치가 발생한 앞 부분에 대하여 다시 비교하지 않고 매칭을 수행, 시간복잡도는O(N+M)
    - 여기서는 구현은 하지 않고 아이디어만 살펴본다.
  
    ```
    p='klmno'
    t="abcklmndefghijklmnop"
    을 비교한다고 했을 때
    
    #고지식한 알고리즘으로 풀 때
    a b c k l m n | d e f g h i j k l m n o p
          k l m n | o     #불일치가 발생했으므로 다음과 같이 한 칸씩 옆으로 민다.
            k l m | n o       -> 1)
              k l | m n o     -> 2)
                k | l m n o   -> 3)
                       
    1)만일 |앞의 패턴인 klm과 그에 대응하는 텍스트인 lmn이 일치할 경우에만 이 단계를 비교하는 것이 의미가 있다.
    2)| 앞의 패턴인 kl과 그에 대응하는 텍스트인 mn이 일치할 경우에만 이 단계를 비교하난 것이 의미가 있다.
    3)| 앞의 패턴인 k와 그에 대응하는 텍스트인 n이 일치하는 경우에만 이 단계를 비교하는 것이 의미가 있다.
    ∴쓸데 없는 3번의 반복을 하는 셈이다.
    
    여기서 앞의 패턴인 klm,kl, k를 접두어, 그에 대응하는 텍스트인 lmn,mn,n을 접미어라 부른다.
    즉, 접두어와 접미어가 일치할 때에만 비교하는 의미가 있다.
    
    
    
    # KMP알고리즘
    따라서 klm과 그에 대응하는 텍스트인 lmn이 일치할 경우, kl과 그에 대응하는 텍스트인 mn이 일치할 경우, k와 그에 대응하는 텍스트인 n이 일치하는 경우에만 비교를 하는 것이 KMP알고리즘이다.
    따라서 이 경우 
    a b c k l m n | d e f g h i j k l m n o p
          k l m n | o 에서
          			k l m n o로 바로 건너뛴다.
    만일 접두어와 접미어가 일치할 경우
    T = ".....a b c d a b c d....."  
    P = "a b c d a b c e"
    .....a b c d a b c | d.....
    	 a b c d a b c | e d와 e의 불일치
    	   a b c d a b | c e 접두어(abcdab)와 접미어(bcbabc) 불일치로 비교X
    	     a b c d a | b c e 접두어(abcda)와 접미어(cdabc) 불일치로 비교X
    	       a b c d | a b c e 접두어(abcd)와 접미어(dabc) 불일치로 비교X
    	         a b c | d a b c e 접두어(abc)와 접미어(abc) 일치, 여기서 부터 비교 시작
    
    
    #위에서는 반복이 일어나는 것 처럼 설명했지만 실제 구현은 아래와 같이 바로 이동하게 된다.
    .....a b c d a b c | d.....  접미어 : abc
    	 a b c d a b c | e     이 위치에서 접미어와 접두어가 일치하는 위치로 옮기면
    	 		 a b c | d a b c e 접두어 : abc  여기서 부터 다시 반복을 시작한다.
    이 경우 텍스트의 인덱스 i는 불일치가 발생한 곳에서 이동할 필요가 없고, 패턴의 인덱스 j도 굳이 0으로 돌아갈 필요 없이 접두어 다음(위의 경우 3)으로 이동하면된다.
    	 		 
    	 		 
    
    만일 이 때 고지식한 알고리즘으로 푼다면
    .....a b c d a b c | d.....
    	 a b c d a b c | e          ->1
    	   	 a b c d a | b c e      ->2
    	   	   a b c d | a b c e    ->3
    	   	     a b c | d a b c e  #KMP알고리즘에선 하지 않았던 위 3번의 반복을 해야 한다.
    ```
  
  - 보이어-무어 알고리즘

    - 패턴의 인덱스만 오른쪽에서 왼쪽으로 비교, 텍스트와 패턴의 비교는 기존처럼 왼쪽에서 오른쪽으로.
    - 대부분의 상용 소프트웨어에서 채택하고 있는 알고리즘
    - 패턴에 오른쪽 끝에 있는 문자가 불일치 하고 이 문자가 패턴 내에 존재하지 않는 경우, 이동 거리는 패턴의 길이만큼 된다.
    - 보이어 무어 알고리즘은 KMP에서 살펴본 접미어 와 맨 마지막 단어 모두를 고려하는데 그 중 맨 마지막 단어만 고려하여 구현하는 심플한 버전을 보이어-무어-horspool 알고리즘 혹은 그냥 horspool알고리즘이라 부른다.
  
    ```
    T = "qwerqwerqwerasd"
    p = "asd"
    q w e r q w e r q w e r a s d
    a s d  #패턴의 오른쪽(d부터)부터 비교 시작e != d이고 패턴에 e가 없으므로 패턴의 길이 만큼 이동
          a s d  d!=w이고 패턴에 w가 없으므로 패턴의 길이만큼 이동
                a s d  똑같은 과정을 반복
          
     
    T = "qweqwewater"
    P = "water"
    q w e q w e w a t e r
          w a t e r #패턴의 오른쪽(r부터)부터 비교 시작, r과 a는 불일치하지만 패턴에 a가 존재는 함
                w a t e r  #a부터 비교 시작
    ```




- 재귀호출을 구현할 때 재귀호출 전에 쓴 내용은 순서대로 진행되고 뒤에 쓴 내용은 역순으로 진행된다.

  ```python
  def f(i,n)
  	if i==n:
          return
      print(i, "hello!") #순서대로 진행
      f(i+1,n)           #재귀함수를 기준으로
      print(i, "hello!") #역순으로 진행
      
  f(0,3)
  
  out
  0 hello!
  1 hello!
  2 hello!
  2 hello!
  1 hello!
  0 hello!
  ```









# 그래프 

- 그래프는 아이템(사물 또는 추상적 개념)들과 이들 사이의 연결 관계를 표현한다.
  - 선형 자료구조(배열)나 트리로 표현하기 어려운 N:N 관계를 표현하기 용이하다.
  - 트리도 그래프의 일종이다(사이클이 없는 그래프).



- 점과 선으로 이루어진 자료 구조
  - 점을 정점(Node 또는 Vortex)이라고 부르고 선을 간선(Edge)라고 부른다.
  - 각 정점에 연결된 간선의 수를 차수(degree)라고 부른다.
  - 일반적으로 정점을 V로, 그 개수를 |V|로 표시하고, 간선을 M으로 간선의 개수를 |M|으로 표시함.
  - |V|개의 정점을 가지고 있는 그래프는 최대 `|V|(|V|-1)/2` 개의 간선이 존재.
  - degree(차수): 해당 노드에 연결된 엣지의 수(혹은 엣지 가중치의 합)



- sparse/dense graph
  - sparse graph: 노드의 수보다 엣지 수가 적은 그래프
  - dense graph: 노드 수보다 엣지 수가 큰 그래프



- 인접과 부속
  - 인접(adjacent): 두 노드가 하나의 엣지로 연결돼 있을 경우
  - 부속(incident): 두 노드가 인접할 경우 두 노드 사이의 엣지는 두 노드에 부속한다.



- 종류

  - 무향 그래프: 화살표가 없는 그래프, 동등한 관계, 양방통행이 가능한 관계
  - 유향 그래프: 화살표가 있는 그래프, 동등하지 않은 관계, 일방통행만 가능한 관계
  - 가중치 그래프: 그래프 사이의 관계에 가중치를 부여하는 그래프, 이동 시간, 비용 등
  - 사이클 없는 방향 그래프(DAG, Directed Acyclic Graph)
  - 완전 그래프: 정점들에 대해 가능한 모든 간선들을 가진 그래프
  - 부분 그래프: 원래 그래프에서 일부 정점이나 간선을 제외한 그래프



- 인접: 두 개의 정점 사이에 간선이 존재하면 서로 인접해 있다고 한다.
  - 완전 그래프에 속한 임의의 두 정점들은 모두 인접해 있다.
  - 만일 유향그래프이고 1->2라면 1번은 2번 정점에 인접해있다고 하지만 2번은 1번 정점에 인접해 있지 않다.



- 경로: 간선들을 순서대로 나열한 것
  - 단순 경로: 경로 중 한 정점을 최대 한 번만 지나는 경로(사이클이 X).

  - 사이클: 임의의 한 정점에서 출발해 자기 자신으로 돌아올 수 있는 경로, 시작한 정점에서 끝나는 경로

    - 임의의 세 노드가 서로 연결되어 있다고 해도 반드시 사이클이 있다고 할 수 는 없다. 무향 그래프일 때는 사이클이 존재하겠지만 유향그래프이면 사이클이 존재 할 수도 있고 하지 않을 수도 있다.



- 그래프의 표현

  - 간선의 정보를 저장하는 방식, 메모리나 성능을 고려해서 결정

  - 인접행렬: |V|*|V|크기의 2차원 배열을 이용해서 간선 정보를 저장

    - 두 정점을 연결하는 간선의 유무를 |V|x|V| 정방(정사각형) 행렬
    - 행 번호와 열 번호는 그래프의 정점에 대응
    - 두 정점이 인접되어 있으면 1, 그렇지 않으면 0으로 표현
    - 만일 |V|가 5,000이면 총 25,000,000의 값을 저장할 2차 배열이 만들어지는데 |E|가 100,000이면 간선의 수에 비해 불필요하게 큰 2차배열을 만든 셈이 된다. 이럴 경우 공간도 낭비되고 최악의 경우25,000,000개의 값을 모두 뒤져야 하기에 굉장히 비효율적이다. 즉 간선이 적은 그래프(희소 그래프)일수록 비효율적일 수 있다.
    - 진입차수와 진출차수를 모두 쉽게 구할 수 있다는 장점이 있다.
    - 무향 그래프일 때 i번째 행의 합 = i번째 열의 합 = V<sub>i</sub>의 차수( V<sub>i</sub>에 연결된 간선의 수)
    - 유향 그래프일 때 행 i의 합=V<sub>i</sub>의 진출 차수, 열 i의 합=V<sub>i</sub>의 진입 차수
  
    ```python
  간선이 있으면 1, 없으면 0
    v = [1,2,3]이고
  1-2
    1-3이면
    [[0,1,1] #1일 경우, 2,3과 간선이 있음
    [1,0,0]  #2일 경우  1과 간선이 있음
    [1,0,0]] #3일 경우  1과 간선이 있음
    
    
    #인접 행렬 구현
    '''
    input
    7 8
    1 2 1 3 2 4 2 5 4 6 5 6 6 7 3 7
    '''
    V, E = map(int,input().split())
    edges = list(map(int,input().split()))
    
    #인접행렬을 생성
    adj = [[0]*(V+1) for _ in range(V+1)]
    
    for i in range(E):
        s,e = edges[2*i], edges[2*i+1]
        #무향그래프일 경우
        adj[s][e]=1
        adj[e][s]=1
    ```
  
  - 인접 리스트: 각 정점에 대한 인접 정점들을 순차적으로 표현
  
    - 하나의 정점에 대한 인접 정점들을 각각 노드로 하는 연결 리스트로 저장 
    - 무방향 그래프일때  `노드 수 = 간선의 수 * 2`, `각 정점의 노드 수 = 정점의 차수`
    - 방향 그래프일 때 `노드 수=간선의 수`, `각 정점의 노드 수=정점의 진출 차수`
    - 진입 차수를 구하기 까다롭다.
  
    ```python
    #input값, 첫 번째 줄에는 순서대로 V와 E의 개수가 주어지고 그 아래로 E개의 간선이 주어진다.
    7 8
    1 2   #무향 그래프
    1 3
    2 4
    2 5
    4 6
    5 6
    6 7
    3 7
    
    V, E = map(int,input().split())
    G = [[] for _ in range(V+1)] #정점은 7까지 있으므로 0번 인덱스는 비워 놓고 7번가지 표현							  하려면 +1을 해줘야 한다.
    for _ in range(E):
        u,v = map(int, input().split())
        G[u].append(v) #유향그래프이고 만일 u에서 v로만 갈 수 있다면 u에다 만 추가 하면 된다.
        G[v].append(u) #무향그래프이기에 u,v를 모두 추가해야한다.
    
    print(G)
    for i in range(1,V+1):
        print(i,G[i])
    
        
    out
    [[], [2, 3], [1, 4, 5], [1, 7], [2, 6], [2, 6], [4, 5, 7], [6, 3]]
    1 [2, 3]  #1번 노드는 2,3번과 연결
    2 [1, 4, 5]
    3 [1, 7]
    4 [2, 6]
    5 [2, 6]
    6 [4, 5, 7]
    7 [6, 3]
    
    
    
    #딕셔너리로 구현
    '''
    input
    7 8
    1 2 1 3 2 4 2 5 4 6 5 6 6 7 3 7
    '''
    
    V, E = map(int,input().split())
    edges = list(map(int,input().split()))
    adj = {i:[] for i in range(1,V+1)}
    for i in range(E):
        s,e = edges[2*i], edges[2*i+1]
        #무향그래프일 경우
        adj[s].append(e)
        adj[e].append(s)
    print(adj)
    ```
  
  - 간선의 배열: 간선(시작 정점, 끝 정점)을 배열에 연속적으로 저장 



- 부분집합과 같이 가상의 상태공간트리를 탐색하며 모든 경우의 수를 고려해보는 완전검색 문제를 풀 때,   매 단계를 선택의 과정으로 생각하는 것이 좋다.
  - 예를 들어 [1,2,3]의 부분집합을 구할 경우 n번째 원소가 들어가는 경우와 들어가지 않는 경우의 2가지 경우의 수가 있다. 따라서 최종적으로 부분집합의 개수는 2<sup>n</sup>개가 있게 된다.
  - 가위바위보를 하는 경우를 생각해 보면 가위바위보는 경우의 수가 3개 이므로 n번 했을 때 나올 수 있는 경우의 수는 3<sup>n</sup>이 된다.
  - 즉 가상의 상태공간 트리는 가위를 선택한 경우, 바위를 선택한 경우, 보를 선택한 경우로 매 선택마다 나뉘게 된다.
  - 이렇게 어떤 선택들을 해야 모든 경우를 탐색할 수 있을지를 생각하면서 문제를 푸는 것이 좋다.



- 그래프 순회는 비선형 구조인 그래프로 표현된 모든 자료(정점)를 빠짐 없이 탐색하는 것을 의미한다.
  - 선형 구조의 경우 인덱스 순으로 순차적으로 탐색하면 되기에 탐색하는 것이 문제 되지 않는다. 그러나 비선형 구조는 어떻게 탐색해야 할지가 문제가 된다.
  - DFS, BFS의 두 가지 방법이 존재한다.
  - DFS(깊이 우선 탐색)
    - 시작 정점의 한 방향으로 갈 수 있는 경로가 있는 곳까지 깊이 탐색해 가다가 더 이상 갈 곳이 없게 되면 가장 마지막에 만났던 갈림길 간선이 있는 정점으로 되돌아와서 다른 방향의 정점으로 탐색을 계속 반복하여 결국 모든 정점을 방문하는 순회 방법
    - 스택을 사용
  - BFS(너비 우선 탐색)
    - 시작 정점의 인접한 정점들을 먼머 모두 차례로 방문한 후에, 방문했던 정점을 시작점으로 하여 다시 인접한 정점들을 차례로 방문하는 방식
    - 큐를 사용



## 서로소 집합

- 서로소 집합(Disjoint-set)

- 서로소 또는 상호 배타 집합들은 서로 중복 포함된 원소가 없는 집합들이다.  다시 말해 교집합이 없다.

- 집합에 속한 하나의 특정 멤버를 통해 각 집합들을 구분한다. 이를 대표자라 한다.

- 상호 배타 집합을 표현하는 방법

  - 연결리스트
  - 트리

- 상호배타 집합 연산

  > alogrithm 폴더에 구현 파일이 있다.

  - Make-Set(x): 원소 x를 유일한 원소로 하는 집합을 생성
  - Find-Set(x): x가 포함된 집합의 대표자를 리턴
  - Union(x,y): x가 포함된 집합과 y가 포함된 집합을 합친다. 대표자를 찾고 대표자들 끼리 연결한다.

- 연결리스트 구현.

  - 같은 집합의 원소들은 하나의 연결 리스트로 관리한다.
  - 연결 리스트의 맨 앞의 원소를 집합의 대표 원소로 삼는다.
  - 각 원소는 집합의 대표원소를 가리키는 링크를 갖는다(대표자 자신도 자신을 가리킨다.).

- 트리로 구현

  - 하나의 집합을 하나의 트리로 표현
  - 자식 노드가 부모 노드를 가리키며 루트 노드가 대표자가 된다(루트 노드도 자기 자신을 가리킨다).

  | 첨자(index) | 0    | 1    | 2    | 3    | 4    | 5    |
  | ----------- | ---- | ---- | ---- | ---- | ---- | ---- |
  | 정점        | a    | b    | c    | d    | e    | f    |
  | 부모        | 0    | 1    | 2    | 2    | 2    | 4    |

  - 위 표는 `a, b, d→c, e→c, f→e`를 표로 나타낸 것이다.
  - 위 표에서 첨자와 정점의 부모가 같으면 해당 정점이 대표자라는 것이다.

  ```python
  #disjoint_set
  def make_set(x):
      p[x]=x
  
  def find_set(x):
      if p[x]==x:
          return x
      else:
          return find_set(p[x])
  
  def union(x,y):
      p[find_set(y)]=find_set(x)
  
  
  N = 8
  p = [0]*(N+1)
  for i in range(1,N+1):
      make_set(i)
  
  union(7,8)
  union(6,7)
  union(5,6)
  union(4,5)
  union(3,4)
  union(2,3)
  union(1,2)
  print(p)
  
  
  out
  #최악의 경우
  [0,1,1,2,3,4,5,6,7]
  
  #이 경우 tree로 구현했음에도
  #1←2←3←4←5←6←7←8의 형태를 띄게 되어 tree로 구현한 의미가 없어진다. 
  ```

  - 문제점: 대표자를 찾기 위해서 루트노드까지 부모 노드를 계속 타고 이동하기에 재귀호출을 여러번 실행해야 한다. 중요한 것은 대표자(루트)가 어느 정점인가 하는 것이지 부모가 어느 정점인지가 아니다. 따라서 이를 빨리 하기 위해 `path compresion`을 사용한다.

    - 트리가 `a→b→c→d→e`로 연결이 되어 있다고 할 때 b에서 루트인 e까지 가기 위해서는 재귀를 3번 실행해야 하고 리턴도 3번 이루어 져야 한다. 
    - 이를 `path compresion`으로 바꿔서 표현하면 다음과 같다. `a→b, b→e, c→e, d→e `

  - 트리로 구현할 때 연산의 효율을 높이는 방법

    - Rank를 이용한 Union: 각 노드는 자신을 루트로 하는 subtree의 높이를 랭크라는 이름으로 저장한다. 두 집합을 합칠 때 rank가 낮은 집합을 rank가 높은 집합에 붙인다. 트리의 높이가 같을 경우 아무렇게나 붙여도 상관 없고 대표자가 된 정점의 랭크를 +1 해준다.

    - path compression: Find-Set을 행하는 과정에서 만나는 모든 조상 노드들이 직접 root(대표자)를 카리키도록 갱신한다(루트까지 가는 경로에 없는 노드들은 갱신되지 않는다.).

      | 노드 | a    | b    | c    | d    | e    | f    | g    | h    |
      | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모 | a    | a    | b    | a    | d    | e    | e    | e    |

      - 위와 같은 트리가 있고 h에서 a까지 가는 과정에서 path compression을 하면 아래와 같이 갱신된다.

      | 노드 | a    | b    | c    | d    | e    | f    | g    | h    |
      | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모 | a    | a    | b    | a    | a    | e    | e    | a    |

      - c, f, g는 h에서 a까지 가는 경로 상에 존재하지 않으므로 갱신되지 않는다. 
      - e, h는 부모 노드가 root로 갱신된다.

  ```python
  #disjoint_set_rank
  def make_set(x):
      p[x]=x
  
  def find_set(x):
      if p[x]==x:
          return x
      else:
          p[x]=find_set(p[x]) #부모 노드를 대표자로 갱신, path compresion
          return p[x]         #최초 인자로 들어온 x에서 대표자까지 가는 재귀를 거치면서 경로상에 있는 모든 노드의 부모 노드가 대표자가 됨
  
  def union(x,y):
      px = find_set(x) #px는 x의 대표자
      py = find_set(y) #py는 y의 대표자
      if rank[px]>rank[py]:   #px의 깊이가 py의 길이보다 크면
          p[py]=px            #px가 대표가 된다.
      else:                   #py의 깊이가 길거나 둘의 깊이가 같으면
          p[px]=py            #py가 대표가 된다.
          if rank[px]==rank[py]:  #만일 둘의 깊이가 같으면
              rank[py]+=1         #대표가 된 py의 깊이에 +1을 해준다.
  
  N = 8
  p = [0]*(N+1)
  rank = [0]*(N+1)  #트리의 깊이를 저장하는 배열
  for i in range(1,N+1):
      make_set(i)
  
  union(7,8)
  union(6,7)
  union(5,6)
  union(4,5)
  union(3,4)
  union(2,3)
  union(1,2)
  print(p)
  
  out
  [0,7,7,7,7,7,7,7,7]
  
  #rank와 path compresion을 적용하지 않은 위 코드와 동일한 코드지만 훨씬 효율적인 트리가 만들어진다.
  
  #깊이를 고려하지 않을 경우 2←3←4인 집합과 1 혼자인 집합이 있을 때
  #union(1,2)를 실행하면 1←2←3←4이 되지만
  #깊이를 고려하면  union(1,2)를 실행해도 1이 2의 자식 노드가 된다.
  ```

  



## 최소 신장 트리

- 그래프에서 최소 비용 문제
  - 모든 정점을 연결하는 간선들의 가중치의 합이 최소가 되는 트리
  - 두 정점 사이의 최소 비용의 경로 찾기
- 신장 트리: N개의 정점으로 이루어진 무방향 그래프에서 n개의 정점과 n-1개의 간선으로 이루어진 트리, 무향그래프의 서브 그래프들 중에서 모든 정점을 포함하는 트리, 트리이므로 사이클이 존재하지 않는다.
- 최소 신장 트리(MST,Minimum Spanning Tree): 무향 가중치 그래 프에서 신장 트리를 구성하는 간선들의 가중치의 합이 최소인 신장 트리
  - MST는 여러개 있을 수 있다.
- MST 표현
  - 그래프
  - 인접행렬
    - 기존 인접행렬이 1, 0으로 간선 유무를 표시했다면 MST를 표현할 때는 간선이 있을 경우 1 대신 가중치를 입력한다.
  - 인접리스트
    - 정점 번호와 가중치를 하나의 리스트로 묶어서 표현
  - 간선들의 배열
    - 시작점, 끝점, 가중치를 리스트에 저장
  - 부모 자식 관계와 가중치에 대한 배열(트리): 현재 정점, 부모 정점, 가중치를 저장



- Prim 알고리즘
  - 하나의 정점에서 연결된 간선들 중에 하나씩 선택하면서 MST를 만들어 가는 방식
    - 임의의 정점을 하나 선택해서 시작
    - 선택한 정점과 인접하는 정점들 중(즉 아래의 트리 정점들 중)에서 최소 비용의 간선이 존재하는 정점을 선택
    - 모든 정점이 선택될 때 까지 위 과정을 반복 
    
  - 서로소인 2개의 집합(2 djsjoint-sets)정보를 유지
    - 트리 정점들: MST를 만들기 위해 선택된 정점들, 이미 선택했으므로 다음 선택의 대상이 되지 않음
    - 비트리 정점들: 선택되지 않은 정점들, 다음 선택의 대상이 된다.
    - 모든 정점들이 트리 정점들이 될 때 까지(모든 정점이 선택될 때 까지 반복하는 것이 Prim알고리즘이다)
    
  - 과정

    - 데이터(괄호 안은 둘 사이의 가중치) 
      
      - 0 → 1(27), 2(26), 5(55), 6(46)  /  1→0, 2(16)  /  2→0, 1, 4(41), 6(20)  /  3 →4(29), 5(13)  / 4→2, 3, 5(35), 6(46)  /  5→0,3,4  /  6→0,2,4
      
    - 정점번호, 부모 정점, 가중치로 구성된 리스트를 생성

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     |      |      |      |      |      |      |      |
      | 가중치(key) |      |      |      |      |      |      |      |

      

    - 부모 노드와 가중치를 각기 -1과 무한대로 초기화

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | -1   | -1   | -1   | -1   | -1   | -1   |
      | 가중치(key) | ∞    | ∞    | ∞    | ∞    | ∞    | ∞    | ∞    |

      

    - 시작정점을 정하고 시작정점의 가중치를 0으로 설정, 이 상태에서 MST가 아니면서 가중치가 최소인 정점을 선택. 현재 선택된정점을 u라 부른다.

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | -1   | -1   | -1   | -1   | -1   | -1   |
      | 가중치(key) | 0    | ∞    | ∞    | ∞    | ∞    | ∞    | ∞    |

    - u를 MST로 선택(트리 정점들 집합에 넣는다)

      

    - u에 인접하고 아직 MST가 아닌 정점(w)들의 가중치와 u와 B 사이의 가중치를 확인 한 후, 정점의 가중치가 u와 w 사이의 가중치보다 크면 가중치를 u와 w 사이의 가중치로 갱신, 부모 정점을 u로 갱신

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | 0    | 0    | -1   | -1   | 0    | 0    |
      | 가중치(key) | 0    | 27   | 26   | ∞    | ∞    | 55   | 46   |

    - 갱신된 가중치들 중 가장 작은 값을 가지는 정점을 MST로 선택

      - 위 예에서 가장 작은 가중치를 가지는 정점은 2번 정점이다.

    - 모든 정점이 선택될 때까지 MST가 아니면서 가중치가 최소인 정점을 선택하는 단계부터 반복

      - 이제 2번 정점이 새로운 u가 되고 위의 과정을 반복하면 아래와 같이 된다. 
      - 이제 새로운 u는 1이 되고 모든 정점이 선택될 때 까지 이 과정을 반복한다.
      - 깊이 우선 탐색과 다르다. 한 정점을 선택했다고 해서 그 정점과 인접한 정점을 쭉 타고 가는 것이 아니라 현재 선택한 정점과 인접한 정점이 아니더라도 매번 갱신을 했을 때 가중치가 최소값이면 그 정점을 선택해서 다음 반복으로 넘어가는 것이다. 

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | 2    | 0    | -1   | 2    | 0    | 2    |
      | 가중치(key) | 0    | 16   | 26   | ∞    | 41   | 55   | 20   |

  - 우선순위 큐로 구현하기도 한다.



- KRUSKAL 알고리즘
  - 정점을 선택하는 Prim과 달리 간선을 선택해서 MST를 찾는 알고리즘
  - 과정
    - 최초에 모든 간선을 가중치에 따라 오름차순으로 정렬
    - 가중치가 가장 낮은 간선부터 선택하면서 트리를 증가시킴, 사이클이 존재하면 다음으로 가중치가 낮은 간선 선택
      - 가중치가 가장 낮은 간선을 선택하기 위해 가중치에 따라 정렬(정렬 알고리즘에 따라 시간복잡도가 크게 상승할 수 있다)
      - 간선을 선택해서 정점이 연결되면 두 정점 중에 대표자를 선택한다. 
      - 사이클 존재 여부는 정점의 대표자가 같은지 여부로 판단하면 된다. 
    - n-1개의 간선이 선택될 때 까지 2번 과정을 반복



## 최단경로

- 최단경로: 간선의 가중치가 있는 그래프에서 두 정점 사이의 경로들 중에 간선의 가중치의 합이 최소인 경로
  - 간선의 가중치가 균일할 때(없을 때)는 BFS로 풀 수 있었다.
  - 가중치가 있을 경우 BFS로 풀 수 없다.
  - 최소신장트리와의 차이점은 최소신장트리가 인접한 모든 노드를 최소비용으로 <u>전부</u> 연결하는 것이라면 최단경로는 두 노드 사이의 거리가 최소인 경로를 찾는 것이다.



- 하나의 시작 정점에서 끝 정점까지의 최단 경로를 구하는 알고리즘(one to all)
  - 다익스트라(dijkstra) 알고리즘
    - 음의 가중치를 허용하지 않음
    - Greedy 적용
    - 시간복잡도는 O(N^2)
  - 벨만-포드(Bellman-Ford)알고리즘
    - 음의 가중치 허용
    - 완전검색(DP) 적용



- 모든 정점들에 대한 최단 경로(all pair)
  - 플로이드-워샬(Floyd-Warshall) 알고리즘
  - 완전검색(DP) 적용



- 다익스트라 알고리즘

  - 시작 정점에서 거리가 최소인 정점을 선택해 나가면서 최단 경로를 구하는 방식
    - MST의 Prim 알고리즘과 유사, 차이는 Prim은 무향 그래프에서만 사용 가능하지만 다익스트라는 무향, 유향 모두 사용 가능하다는 점과 가중치를 갱신하는 방식에서 차이가 있다.
  - 최적 부분 구조
    - 시작정점(s)에서 끝 정점(t) 까지의 최단 경로에 정점 x가 존재한다.
    - 이때, 최단경로는 s에서 x까지의 최단 경로와 x에서 t까지의 최단경로로 구성된다.
  - 간선 완화: Prim과 마찬가지로 최초 가중치를  무한으로 설정하고 실제 가중치를 구한 후 최초 가중치와 실제 가중치를 비교하여 더 작은 가중치로 갱신한다.
  - 정점들을 3개의 집합으로 구분
    - 출발점에서 최단경로를 찾은 정점들(간선완화 완료)
    - 출발점에서 아직 최단경로를 찾지는 않았으나 출발점에서 가는 경로를 적어도 하나 찾은 정점들(간선완화를 하지 않은 정점들)
    - 아직 출발점에서 가는 경로를 하나도 찾지 못한 정점들
  - 예시
    -  `1 - 2 - 3` 과 같은 경로가 존재할 때 1-2는 가중치가 1, 2-3은 가중치가 2라고 하고 1-3은 간선이 존재하지 않으므로 무한대라고 가정
    - 시작 위치를 1로 설정했을 때 갈 수 있는 경로 중에서 최단경로는 가중치가 1인 2번 정점이다. 따라서 다음 정점으로 2번을 선택
    - 2번 정점을 선택했을 때 시작 정점인 1번 정점에서 2번 정점을 거치면 3이라는 가중치로 3번 정점으로 갈 수 있다는 것을 알 수 있다.
    - 무한대보다는 3이 작으므로, 1-3의 가중치를 무한대에서 3으로 조정(간선 완화)
    - 다음 정점까지의 최단거리만 선택(탐욕적 선택)했음에도 최단 거리를 구하게 됨.





# Stack과 Queue

## Stack

- 물건을 쌓아 올리듯 자료를 쌓아 올린 형태의 자료구조
- 선형 구조: 자료 간의 관계가 1:1의 관계를 가진다(비선형구조는 1:N의 관계). 
- 마지막에 삽입한 자료를 가장 먼저 꺼낸다(후입선출).

- 스택의 사용을 위해 필요한 연산
  - push: 저장소에 자료를 삽입(저장)
  - pop: 저장소에서 자료를 꺼낸다(삽입한 자료의 역순)
  - isEmpty: 스택이 공백인지 아닌지 확인
  - peek: 스택의 top에 있는 원소를 반환하는 연산



- DFS 구현에 사용된다.

  - 반복으로 구현한 DFS

  ```python
  '''
  input
  7 8
  1 2 1 3 2 4 2 5 4 6 5 6 6 7 3 7
  '''
  def dfs(v):
      s = []
      visited = [0]*(V+1)
      s.append(v)
      while s:
          u = s.pop()
          if visited[u]==0:
              print(u,end = " ")
              visited[u]=1
              for i in range(1,V+1):
                  if adj[u][i]==1 and visited[i]==0:
                      s.append(i)
  
  V, E = map(int,input().split())
  edges = list(map(int,input().split()))
  
  #인접행렬을 생성
  adj = [[0]*(V+1) for _ in range(V+1)]
  
  for i in range(E):
      s,e = edges[2*i], edges[2*i+1]
      #무향그래프일 경우
      adj[s][e]=1
      adj[e][s]=1
    
  out
  1 3 7 6 5 2 4
  ```
  
  



## Queue

- queue
  - 삽입과 삭제의 위치가 제한적인 자료구조(큐의 뒤에서는 삽입만 하고 큐의 앞에서는 삭제만 이루어진다)
  - 선입선출구조



- 큐의 사용을 위해 필요한 연산

  > 보통 함수의 이름을 아래와 같이 정의하여 사용한다. 함수명은 정의하는 사람 마음이지만 아래와 같이 정의했을 경우 모르는 사람이 봐도 Queue를 사용하고 있다는 것을 바로 알 수 있다는 장점이 있다.

  - enQueue(item): 큐의 뒤쪽(rear)에 원소를 삽입(rear+=1)
  - deQueue(): 큐의 앞쪽(front)에 원소를 삭제하고 반환(front+=1)
  - createQueue():공백 상태의 큐를 생성(front=rear=-1)
  - isEmpty():큐가 공백 상태인지 확인(front==rear)
  - isFull(): 큐가 포화 상태인지 확인(rear==n-1, n은 배열의 크기)
  - Qpeek(): 큐의 앞쪽에서 원소를 삭제 없이 반환



- BFS 구현에 사용된다.

  

- 우선순위 큐: 우선순위를 기준으로 순위가 높은 데이터를 먼저 꺼낸다.



- 데크(Deque): 큐 두 개 중 하나를 좌우로 뒤집어서 붙인 구조, 큐의 양쪽 끝에서 삽입과 삭제를 수행할 수 있도록 확장한 구조

  



# Linked list

- 연결리스트는 일반 리스트에 비해 인덱스의 조회는 느리지만 추가, 삭제는 빠르다.

- 단일 연결 리스트에서 삽입, 삭제를 할 때에는 앞 쪽에 있는 노드에 대한 정보를 알아야 한다. 따라서 앞 쪽 노드에 대한 정보 탐색을 가장 먼저 해야 한다.

  - 각 노드는 데이터 필드와 다음 노드에 대한 주소를 가지고 있다.

  - 즉 이전 노드에는 다음 노드에 대한 주소가 존재한다.

  - 만일 새로운 노드를 추가하고자 한다면 앞의 노드가 가리키는 노드를 새로운 노드가 가르키도록 변경하고 앞쪽 노드는 추가한 노드를 가리키게 한다. 즉, 둘 다 앞 쪽 노드를 알아야 가능하다.

  - 삭제도 마찬가지로 앞쪽 노드가 가르키는 노드를 삭제할 노드가 가르키는 노드로 변경하면 된다.

    ex. 서울-부산이 있을 때 중간에 대전을 추가하고 싶다면 우선 첫 번째로 서울이 가리키는 부산이라는 주소를 읽어와서 대전의 주소로 만들고 서울이 가리키는 주소를 대전으로 변경한다. 만일 서울-대전-부산에서 대전을 빼고 싶다면 서울이 카르키던 대전을 부산으로 바꾸면 된다.

    

- 연결 리스트에서 뭘 먼저 연결해야 할지 헷갈린다면 삽입해야 할 노드의 주소를 먼저 수정하는 것이 안전하다.



- 삽입정렬(배열의 요소 별로 배열을 쭉 순회하면서 요소보다 작은 값과 큰 값 사이에 해당 요소를 삽입하여 정렬하는 방식)은 연결리스트로 구현하는 것이 더 효율적이다.
  - 일반리스트의 경우 삽입 후 삽입한 위치 뒤의 요소들은 모두 한 칸씩 뒤로 밀어야 한다는 단점이 있다.
  - 연결리스트로 구현하면 앞뒤 요소와 연결만 해주면 된다.

 

- 병합정렬 역시 연결 리스트로 구현하면 더 효율적이다.



- 원형 연결리스트는 원형이기에 tail은 잘 쓰지 않는다. head는 원형 연결 리스트의 시작점을 의미한다.
  - 모든 노드의 next와 prev에 None이 존재하지 않는다.







# Tree

1. 트리 개요

- 용어 정리
  - 노드: 트리의 원소
    - 루트 노드: 트리의 시작 노드
    - 조상 노드: 간선을 따라 루트 노드까지 이르는 경로에 있는 모든 노드들
    - 자손 노드: 서브 트리에 있는 하위 레벨의 노드들
    - 형제 노드: 같은 부모 노드의 자식 노드들
    - 단말 노드: 자식 노드가 없는 노드
  - 간선: 노드를 연결하는 선, 부모 노드와 자식 노드를 연결
    - 트리에서 간선의 수는 반드시 노드의 수-1개이다.
    - 즉 노드의 수>=간선의 수라면 트리가 아니다.
  - 서브트리: 부모 노드와 연결된 간선을 끊었을 때 생성되는 트리
    - 즉, 트리는 0개 이상의 하위 트리로 구성되어 있다.
  - 차수
    - 노드의 차수: 노드에 연결된 자식 노드의 수
    - 트리의 차수: 트리에 있는 노드의 차수 중에서 가장 큰 값
  - 높이(레벨)
    - 노드의 높이: 루트에서 노드에 이르는 간선의 수
    - 트리의 높이: 트리에 있는 노드의 높이 중에서 가장 큰 값
- 트리는 일종의 그래프이다. 
  - 그래프는 연결컴포넌트(어떤 임의의 두 노드를 선택하든지 둘 사이에 경로가 존재)
  - 트리 역시 연결컴포넌트 이지만 임의의 두 노드 사이에 유일한 경로가 존재한다. 즉 그래프와는 달리 두 노드 사이에 경로가 단 하나뿐이다.
  - 사이클이 존재하지 않는다. 즉 어떤 한 간선이라도 지우면 모든 노드가 연결된 상태는 아니게 되며 간선을 하나라도 추가하면 사이클이 생기게 된다(∵노드수=간선수+1).
- 트리의 특징
  - 트리는 어떤 자료를 더 낮은 시간복잡도로 찾거나 삽입하거나 삭제하기 위해 사용한다.
    - 수직으로 뻗은 리스트를 가정하고 그 리스트 내의 어떤 값을 찾으려 한다면 시간복잡도는 O(N)이 될 것이다. 그러나 만일 일정한 규칙에 따라 트리 형태로 구성되어 있다면 시간 복잡도는 O(logN)이 될 것이다. 
    - 예를 들어 왼쪽 자식 노드에는 부모 보다 작은 값, 오른쪽 자식 노드에는 부모보다 큰 값이 저장되어 있다고 할 때 찾으려는 값이 부모보다 작다면 오른쪽 서브트리는 탐색을 하지 않아도 된다. 또 다시 왼쪽 서브트리로 들어가서 여전히 왼쪽 서브트리의 부모 보다 찾으려는 값이 작다면 다시 왼쪽 서브트리의 오른쪽 서브트리는 탐색을 하지 않아도 된다. 이런 식으로 자료를 더 효율적으로 탐색, 수정, 삭제 할 수 있게 된다.
    - 편향 트리가 트리로서의 의미가 없다고 하는 이유도 여기에 있다. 한쪽으로 편향되어 있다면 수직으로 뻗은 리스트와 다를 것이 없으므로 트리를 쓰는 의미가 없다.
  - 루트(최상위 원소)에서 하위 원소로 내려가면서 확장되는 뿌리 모양의 구조
  - 가계도를 생각하면 쉽다.  실제로 가계도에서 많은 용어를 가져 왔다.
  - 비선형 자료구조
  - 하나(반드시 하나)의 부모 노드 아래에 0개 이상의 자식 노드가 존재하는 형태(원소들 간 1:n의 관계를 가진다)
  - 한 개 이상(∵루트는 반드시 존재)의 노드로 이루어진 유한 집합이다.
  - 루트를 제외한 나머지 노드들은 0개 이상의 분리집합(서로소)이다. 즉 한 집합 내부에 있는 원소가 다른 집합의 원소가 될 수는 없다.



2. 이진트리

- 이진트리
  - 모든 노드들이 최대 2개의 서브트리를 갖는 특별한 형태의 트리(0~2개의 자식 노드가 존재)
    - 레벨(높이) i에서 노드의 최대 개수는 2<sup>i</sup>개
    - 높이가 h인 이진 트리가 가질 수 있는 노드의 최소 개수는 (h+1)개(모든 높이에 노드가 1개씩만 있는 경우), 최대 개수는 (2<sup>h+1</sup>-1)개
  - 왼쪽 자식과 오른쪽 자식을 구분한다.

- 포화 이진 트리
  - 모든 레벨에 노드가 포화 상태로 차 있는 이진 트리(모든 높이에 노드가 2개씩 존재하는 트리)
  - 루트를 1번으로 하여 모든 노드가 번호를 가진다. 이 경우 가장 왼쪽의 노드를 쭉 타고 가면 번호는 2<sup>높이</sup>로 매겨진다. 오른쪽은 2<sup>높이+1</sup>-1로 매겨진다.
  
- 완전 이진 트리
  
  - 높이가 h이고 노드가 n개일 때, 포화 이진 트리의 노드 번호 1번부터 n번 까지 빈자리가 없는 이진 트리, 즉 포화 이진트리는 아니지만 n번째 노드까지는 포화 이진 트리의 형태를 지닌다.
  
- 편향 이진 트리(사실상 연결리스트이다)
  - 높이 h에 대한 최소 개수의 노드를 가지면서 한쪽 방향의 자식만을 가진 이진 트리, 즉 노드가 2개 이상이거나 왼쪽자식, 오른쪽 자식이 혼재되어 있으면 편향 이진 트리가 아니다.
    - 왼쪽 편향 이진 트리
    - 오른쪽 편향 이진 트리
  - 트리의 장점을 잘 살리지 못하기에 좋지 않은 구조다.

- 이진트리에서의 순회(DFS를 사용)

  - 기본적인 순회 방법
    - 왼쪽 자식을 오른쪽 자식보다 먼저 방문한다는 원칙 하에 부모 노드를 언제 방문할지에 따라 3가지로 나뉜다.
    - 레벨 순회: 부모부터 차례로 방문 후 자식을 방문(BFS와 동일)
    - 전위 순회:부모노드 방문 후, 자식 노드 좌,우 순 방문(일반적 DFS와 동일)
    - 중위 순회: 왼쪽 자식, 부모노드, 오른쪽 자식 순으로 방문
    - 후위 순회: 좌,우 자식 방문 후 , 부모 노드  순으로 방문
  - 이진 트리 순회시 모든 부모 노드는 3번 방문한다.
    - 처음 노드에 진입할 때(이 때 방문 표시(혹은 원하는 처리)를 하면 전위 순회), A-B-D-E-H-I-C-F-G
    - 왼쪽 자식에서 돌아올 때(이 때 방문 표시(혹은 원하는 처리)를 하면 중위 순회),D-B-H-E-I-A-F-C-G
    - 오른쪽 자식에서 돌아올 때 (이 때 방문 표시(혹은 원하는 처리)를 하면 후위 순회)D-H-I-E-B-F-G-C-A

  | A    |      |      |      |      |      |
  | ---- | ---- | ---- | ---- | ---- | ---- |
  | B    |      |      | C    |      |      |
  | D    | E    |      | F    | G    |      |
  |      | H    | I    |      |      |      |

- 이진트리의 표현

  - 1차원 배열에 표현이 가능하다

  - 노드 번호가 i인 노드의 왼쪽 자식의 노드 번호는 2*i
  - 노드 번호가 i인 노드의 오른쪽 자식의 노드 번호는 2*i+1
  - 부모는 i//2(왼쪽 자식이던 오른쪽 자식이던 마찬가지다 ∵ //는 나머지를 버리므로 +1이 되던 안되던 상관 없다.)



- 수식트리
  - 수식을 표현하는 이진트리
  - 연산자는 부모, 피연산자는 좌,우의 자식 노드가 된다.
  - 단말 노드는 피연산자, 단말 노드가 아닌 노드(루트 노드와 가지 노드)는 모드 연산자
  - 단말노드(leaf)에 가까울수록 연산의 우선 순위가 높아진다.



- 이진 탐색 트리

  - 탐색 작업을 효율적으로 하기 위한 자료 구조
  - 모든 원소는 서로 다른 유일한 키를 갖는다
  - key는 왼쪽 자식<부모<오른쪽 자식 이다. 즉 왼쪽 서브트리는 루트보다 작은 값이, 오른쪽 서브트리는 루트보다 큰 값이 온다. 각각의 서브트리 역시 이진 탐색 트리가 된다.
  - 중위 순회를 하면 오름차순으로 정렬된 값을 얻을 수 있다.
  - 구체적 탐색 순서
    - 루트에서 시작
    - 탐색할 키 값 x를 루트 노드의 키 값과 비교
    - 루트 노드의 키 값>x 면 왼쪽 서브트리로 로 이동
      - 왼쪽 서브트리에서 다시 처음부터 시작
    - 루트 노드의 키 값<x 면 오른쪽 서브트리로 로 이동
      - 오른쪽 서브트리에서 다시 처음부터 시작
    - 루트 노드의 키 값==x 면 x를 찾음
  - 삽입 연산
  
- 위의 과정을 거쳐 탐색을 수행 후 탐색이 실패한 위치(삽입 하려는 값이기에 당연히 탐색해도 없을 것이므로 탐색은 실패하게 된다)에 삽입하려는 값을 삽입
  
- 삭제 연산
  
  - 삽입과 마찬가지로 탐색을 수행 후 찾으면 삭제
  
  - 삭제 후 만일 삭제한 노드에 자식이 있었다면 삭제한 노드의 부모 노드와 삭제한 노드의 자식노드를 연결해준다.
  
  - 만일 삭제한 노드의 자식 노드가 2개 였다면 왼쪽 서브트리의 가장 큰 값이나 오른쪽 서브트리의 가장 작은 값 중 하나가 삭제한 노드의 자리를 대체해 새로운 부모 노드가 된다.
  
    ∵key는 왼쪽 서브트리<루트 노드<오른쪽 서브트리
      - 왼쪽 서브트리의 가장 큰 값은 왼쪽 서브트리에서 오른쪽으로 갈 수 있을 때 까지 가면 가장 큰 값이 나오며
      - 오른쪽 서브트리의 가장 작은 값은 오른쪽 서브트리에서 왼쪽으로 갈 수 있을 때 까지 가면 가장 작은 값이 나온다.
  
  - 이진 탐색 트리에서 탐색, 삽입, 삭제 시간은 트리의 높이 만큼 걸린다.
    - 이진 트리가 균형적으로 생성되어 있는 경우(좌,우 서브트리의 높이차가 1이하): 대략 O(log n)
    - 최악의 경우: 한쪽으로 치우친 경사 이진트리의 경우: O(N)



3. 힙(heap)

- 우선순위 큐(큐에 들어간 순서가 아닌, 우선순위에 따라 처리)를 구현하기 위해 사용
- 노드를 완전 이진 트리 형태로 저장하여 구현하여 트리에 있는 노드 중에서 키값이 가장 큰 노드나 키값이 가장 작은 노드를 찾기 위해서 만든 자료구조
- 힙을 정의하는 2가지 요소(둘 중 하나라도 충족하지 못하면 힙이 아니다)
  - 완전 이진 트리이다.
  - 부모 요소와 자식 요소 사이 키 값의 대소에 일관성이 존재한다.
    - 항상 부모 요소의 키 값이 크다(최대힙)
    - 항상 부모 요소의 키 값이 작다(최소힙)
- 즉, 우선순위 큐에서는 가장 작은 값이나 가장 큰 값을 먼저 처리하는데 자료의 추가나 삭제가 빈번히 일어나는 경우에 추가나 삭제가 일어날 때 마다 번번이 추가된 자료나 삭제된 자료를 고려하여 다시 크기 순으로 정렬하고  최대값이나 최솟값을 다시 찾아야 하는 번거로움이 있다. 그러나 힙에서는 항상 루트에 최소값(최소 힙)이나 최대값(최대 힙)을 위치시키기 때문에 다른 값의 정렬 여부와 관계 없이 항상 최대값, 혹은 최소값을 알 수 있다. 따라서 시간이 훨씬 적게 걸린다.
  - 따라서 최대값, 최솟값을 탐색하는 시간 복잡도는 O(1)이다.
- 종류
  - 최대 힙
    - 키 값이 가장 큰 노드를 찾기 위한 완전 이진 트리
    - 부모노드의 키값>자식노드의 키값, 이진 트리와 달리 자식들(좌우) 사이의 키값의 대소는 상관 없다.
    - 루트 노드: 키값이 가장 큰 노드
  - 최소 힙
    - 키 값이 가장 작은 노드를 찾기 위한 완전 이진 트리
    - 부모노드의 키값<자식노드의 키값, 이진 트리와 달리  자식들(좌우) 사이의 키값의 대소는 상관 없다.
    - 루트 노드: 키값이 가장 작은 노드
- 특정 노드의 자식 노드가 있는지 확인하는 방법
  - 일반적으로 트리의 마지막 노드를 알 수 있다.
  - 따라서 만일 노드번호\*2를 했을 때 이 값이 트리의 마지막 노드 번호보다 크다면 자식 노드가 없는 것이다. 만일 같다면 왼쪽 자식 하나만 가지고 있는 것이고 노드번호\*2+1이 마지막 노드 번호보다 작거나 같다면 좌우 자식이 모두 있는 것이다.





# 반복과 재귀

- 반복과 재귀는 유사한 작업을 수행할 수 있다.
- 반복은 수행하는 작업이 완료될 때 까지 계속 반복
- 재귀는 주어진 문제의 해를 구하기 위해 동일하면서 더 작은 문제의 해를 이용하는 방법
  - 하나의 문제를 해결할 수 있는(해결하기 쉬운) 더 작은 문제로 쪼개고 결과들을 결합한다.
  - 재귀함수로 구현



- 반복

  - 초기화: 반복되는 명령문을 실행하기 전에 (한번만)조건 검사에 사용할 변수의 초기값 설정
  - 조건검사
  - 반복할 명령문 실행
  - 엡데이트: 무한루프가 되지 않게 조건이 거짓이 되게 한다.

  ```python
  #e.g 2**k를 구하는 함수
  
  def power_of_2(k):
      #초기화
      i=0
      power=1
      #조건검사
      while i<k:
      #명령문 실행
      	power=power*2
          #업데이트
          i+=1
      
  ```

  



- 재귀적 알고리즘
  - 재귀적 정의는 두 부분으로 나뉜다.
  - 하나 또는 그 이상의 기본 경우(base case or rule): 집합에 포함되어 있는 원소로 induction을 생성하기 위핸 시드(seed) 역할
  - 하나 또는 그 이상의 유도된 경우(inductive case or rule): 새로운 집합의 원소를 생성하기 위해 결합되어 지는 방법



- 재귀함수
  - 함수 내부에서 직접 혹은 간접적으로 자기 자신을 호출하는 함수
  - 일반적으로 재귀적 정의를 이용해 재귀함수를 구현
  - 따라서, 기본 부분과 유도 부분으로 구성된다.
  - 재귀적 프로그램을 작성하는 것은 반복 구조에 비해 간결하고 이해하기 쉽다.
  - 함수 호출은 프로그램 메모리 구조에서 스택을 사용한다. 따라서 재귀 호출은 반복적은 스택의 사용을 의미하며 메모리 및 속도에서 성능저하가 발생

```python
#e.g.팩토리얼 재귀 함수
def fact(n):
    #basic
    if n<=1:
        return 1
    #inductive
    else:
        return n*fact(n-1)
```



- 해결할 문제를 고려하여 반복이나 재귀의 방법을 선택
  - 재구니느 문제 해결을 위한 알고리즘 설계가 간단하고 자연스러움
    - 추상자료형(list, tree 등)의 알고리즘은 재귀가 구현이 간단하고 자연스러운 경우가 많다.
  - 일반적으로 재귀적 알고리즘은 반복 알고리즘보다 더 많은 메모리와 연산을 필요로 한다.
    - 가지치기를 잘 하거나 데이터 양이 적은 경우 재귀가 더 효율적일 수 있다.
  - 입력값 n이 커질수록 재귀 알고리즘은 반복에 비해 비효율적일 수 있다.

|                | 재귀                                    | 반복                |
| -------------- | --------------------------------------- | ------------------- |
| 종료           | 재귀 함수 호출이 종료되는 베이스 케이스 | 반복문의 종료 조건  |
| 수행 시간      | 상대적으로 느림                         | 빠름                |
| 메모리 공간    | 상대적으로 많이 사용                    | 적게 사용           |
| 소스 코드 길이 | 짧고 간결                               | 길다                |
| 소스 코드 형태 | 선택구조(if...else)                     | 반복구조(for,while) |
| 무한 반복시    | 스택 오버플로우                         | CPU를 반복해서 점유 |



- brute-force
  - 문제 해결을 위한 간단하고 쉬운 접근법
  - force의 의미는 사람(지능)보다는 컴퓨터의 force를 의미한다.

  - 대부분의 문제에 적용 가능
  - 상대적으로 빠른 시간에 문제 해결(알고리즘 설계)을 할 수 있다.
  - 문제에 포함된 자료의 크기가 작다면 유용하다
  - 학술적 또는 교육적 목적을 위해 알고리즘의 효율성을 판단하기 위한 척도로 사용된다.

  

- 완전검색
  - 완전검색은 조합적 문제에 대한 brute-force 방법이다.
    - 이들은 전형적으로 순열, 조합, 그리고 부분집합과 같은 조합적 문제들과 연관된다.
    - 많은 종류의 문제들이 특정 조건을 만족하는 경우나 요소를 찾는 것이다.
  - 모든 경우의 수를 생성하고 테스트하기에 수행 속도는 느리지만 해답을 찾지 못할 확률이 작다.
  - 우선 완전검색으로 접근하여 해답을 도출한 후, 성능 개선을 위해 다른 알고리즘을 사용하고 해답을 확인하는 것이 바람직하다.







# 순열과 조합, 부분집합

## 순열



- 순열: 서로 다른 것들 중 몇 개를 뽑아서 한 줄로 나열하는 것

  - 다수의 알고리즘 문제들은 순서화된 요소들의 집합에서 최선의 방법을 찾는 것과 관련 있다.
  - 서로 다른 n개 중 r개를 택하는 순열은 <sub>n</sub>P<sub>r</sub>로 표현한다.
  - <sub>n</sub>P<sub>n</sub>=n! 이다.

- 순열 생성 방법

  - 사전적 순서(Lexicographic-Order)

  - 최소 변경을 통한 방법(Minimum-exchange requirement)

    - 각각의 순열들은 이전의 상태에서 단지 두 개의 요소들을 교환해서 생성
    - [123], [<u>21</u>3], [2<u>31</u>], [<u>32</u>1], [3<u>12</u>], [<u>13</u>2]

  - 순열 생성 알고리즘

    - 반복문을 중첩하여 생성

    - 재귀호출을 통한 순열 생성

    - 재귀호출을 통한 순열 생성-교환을 활용

      - 예제:swea_1244_최대상금




## 부분집합

- 집합에 포함된 원소들을 선택하는 것
- 다수의 중요 알고리즘들이 원소들의 그룹에서 최적의 부분 집합을 찾는 것이다
- N개의 원소를 포함한 집합
  - 자기 자신과 공집합을 포함한 모든 부분집합(power set)의 개수는 2<sup>n</sup>대
  - 원소의 수가 증가하면 부분집합의 개수는 지수적으로 증가
- 부분집합 생성 알고리즘
  - 반복문을 중첩하여 생성
  - 바이너리 카운팅
    - 원소 수에 해당하는 N개의 비트열을 이용한다.
    - n번째 비트값이 1이면 n번째 원소가 포함되었음을 의미한다.



## 조합

- 서로 다른 n개의 원소 중 r개를 순서 없이 골라낸 것을 조합이라고 부란다.

- 조합의 수식
  $$
  _nC_k=\frac{n!}{(n-k)!k!}   (단, n>k)
  $$

  - <sub>n</sub>C<sub>r</sub> = <sub>n-1</sub>C<sub>r-1</sub>+<sub>n-1</sub>C<sub>r</sub>(재귀적 표현, <sub>n</sub>C<sub>r</sub>이라는 동일한 함수를 사용, inductive rule로 쓸 수 있다)
  - <sub>n</sub>C<sub>0</sub> = 1(base rule로 쓸 수 있다)
  - <sub>n</sub>C<sub>n</sub> = 1

- 조합을 재귀로 구하기

  - arr = [0,1,2,3,4]일 때
  - <sub>5</sub>C<sub>3</sub>은 (4가 포함된 경우 + 4가 포함되지 않은 경우)이다. 즉 <sub>5</sub>C<sub>3</sub> = <sub>4</sub>C<sub>2</sub>(4포함)+<sub>4</sub>C<sub>3</sub>(4미포함)
  - <sub>n</sub>C<sub>0</sub> = 1라는 base rule을 사용







# 탐욕 알고리즘

- 탐욕(greedy) 알고리즘
  - 최적해를 구하는 데 사용되는 근시안적인 방법, 반드시 최적해를 구한다는 보장이 없다.
  - 일반적으로, 머리속에 떠오르는 생각을 검증 없이 바로 구현하면 greedy 접근이 된다.
  - 여러 경우 중 하나를 선택 할 때마다 그 순간에 최적이라고 생각되는 것을 선택해 나가는 방식으로 진행하여 최종적인 해답에 도달
  - 각 선택 지점에서 이루어지는 결정은 지역적으로는 최적이지만, 그 선택들을 계속 수집하여 최종적인 해답을 만들었다고 하여, 그것이 최적이라는 보장은 없다. 
  - 일단, 한 번 선택된 것은 번복하지 않는다. 이런 특성 때문에 대부분의 탐욕 알고리즘들은 단순하며, 또한 제한적인 문제들에 적용된다.
  - 매 순간의 선택이 최적이라는 것이 논리적으로 타당해야 한다.



- 최적화(optimization) 문제란 가능한 해들 중에서 가장 좋은(최대 또는 최소) 해를 찾는 문제이다.
  - 대부분의 최적화 문제는 완전검색으로 풀어야 하는 문제들이다.
  - 따라서 시간이 오래 걸리므로 보다 빠르게 찾기 위해 탐욕 알고리즘을 사용한다.
  - 그러나 탐욕으로 풀 수 있는 최적화 문제는 많지 않다.



- 동작 과정
  - 해 선택: 현재 상태에서 부분 문제의 최적 해를 구한 뒤, 이를 부분해 집합(Solution Set)에 추가한다.
  - 실행 가능성 검사: 새로운 부분 해 집합이 실행가능한지를 확인한다. 즉 문제의 제약 조건을 위반하지 않는지 검사한다
  - 해 검사: 새로운 부분 해 집합이 문제의 해가 되는지 확인, 아직 전체 문제의 해가 완성되지 않았다면 1의 해 선택부터 다시 시작한다.
  - 예시: 거스름돈 줄이기
    - 2370원을 거슬러 줘야 하는 경우 최소한의 화폐로 거스름돈을 줘야 한다.
    - 따라서 1000원을 부분해 집합에 추가, 1370이 남음
    - 다시 1000원을 부분해 집합에 추가, 370이 남음
    - 다시 1000원을 부분해 집합에 추가, 실행 가능성 검사에서 문제의 제약조건에 위배되어 다시 1000원을 부분해 집합에서 뺀 후 해 선택으로 돌아감, 100원을 3번 추가, 10원을 7번 추가
    - 해 검사 결과 문제의 해가 되었으므로 종료



- 탐욕 알고리즘의 필수 요소
  - 탐욕적 선택 속성
    - 탐욕적 선택은 최적해로 갈 수 있음을 보여라
    - 즉 탐욕적 선택은 항상 안전하다.
  - 최적 부분 구조
    - 최적화 문제를 정형화하라
    - 하나의 선택을 하면 풀어야 할 하나의 하위 문제가 남는다
  - 원문제의 최적해 = 탐욕적 선택+하위 문제의 최적해 임을 증명하라



- 탐욕 기법과 동적 계획법의 비교
  - 탐욕
    - 완전검색을 하지 않기 위해 사용한다.
    - 매 단계에서 가장 좋게 보이는 것을 선택, 지역 최적 선택(local optimal choice)
    - 하위 문제를 풀기 전에 탐욕적 선택이 먼저 이루어진다.
    - Top-down 방식
    - 일반적으로 빠르고 간결(완전검색을 하지 않는다.)
    - 장점이 많음에도 쓰이지 않는 이유는 탐욕으로 푸는 방법을 찾은 문제가 많지 않기 때문이다. 최적화 문제를 풀기 위한 알고리즘이지만 최적화 문제 중에서도 탐욕으로 푸는 방법을 아직 찾지 못한 문제들이 많이 있다.
  - 동적 계획법
    - 기본적으로 완전검색이다(보다 효율적인 완전 검색).
    - 매 단계의 선택은 해결한 하위 문제의 해를 기반으로 한다.
    - 하위 문제가 우선 해결된다.
    - Bottom-up 방식
    - 좀 더 느리고, 복잡(완전검색을 한다)
    - 탐욕과 달리 대부분의 문제에 적용 가능하다.



- 대표적인 탐욕 기법의 알고리즘들
  - Prim,Kruskal,Dijkstra 등









# Divide and Conquer

- 분할정복: 문제를 부분 문제로 나눠(divide)서 부분문제의 해를 구한 후(conquer,) 부분문제의 해를 통해 전체 문제를 해결(combine)하는 방식
- Top-down Approach
 - divide ,conquer, combine의 세 단계를 거쳐 문제를 해결한다.
   - 이 때 부분문제가 더 작은 부분문제로 나뉠 수 있다면 문제가 충분히 작아질 때 까지 conquer 또한 다시 divde,conquer,combine으로 나뉘게 된다.
   - 위의 설명에서 알 수 있듯이 재귀함수와 매우 밀접한 연관을 지니는 패러다임이다.
   - 1~8의 합을 구할 경우 아래 그림과 같이 더 작은 문제들로 분할하여 base case인 1~1의 합 ~ 8~8의 합을 구한 후 이를 통해 상위문제의 해를 구하는 식으로 합을 구한다.



- 병합정렬
  - 리스트를 절반으로 나누고(divide), 왼쪽과 오른쪽을 각각 정렬(conquer)한 후, 정렬된 두 리스트를 하나의 정렬된 리스트로 합병(combine)한다.
  - 세 과정 중 합병이 가장 까다롭다.
  - 코드는 알고리즘 폴더 참조



- 퀵정렬

  - 합병정렬과 달리 세 과정 중 나누는과정이 가장 까다롭다.
  - 퀵 정렬에서 리스트를 나누는 과정(divide)을 파티션(partition)이라 부른다.
    - 기준점(pivot)을 정한다(divide). 꼭 리스트의 중간에 있는 값일 필요는 없다.
    - 기준점보다 더 작은 값은 기준점 왼쪽으로, 큰 값은 기준점 오른쪽으로 정렬한다(conquer).
  - 코드는 알고리즘 폴더 참조

  

- 이진 탐색

  - 중간값을 기준으로 계속해서 탐색 범위를 좁혀가며 탐색

  - 과정
    - 자료의 중앙에 있는 원소 선택
    - 중앙 원소의 값고 찾고자 하는 목표값을 비교
    - 목표값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행, 크다면 자료의 오른쪽 반에 대해 새로 검색을 수행
    - 찾고자 하는 값을 찾을 때까지 위 과정을 반복
  - 코드는 알고리즘 폴더 참조





# Backtracking

- 백트레킹 개념
  - 여러가지 선택지들이 존재하는 상황에서 한가지를 선택한다.
  - 선택이 이루어지면 새로운 선택지들의 집합이 생성된다.
  - 이런 선택을 반복하면서 최종 상태에 도달한다.
  - 초기상태에서 목표상태까지 상태 공간 트리를 탐색하면서 진행된다.
  - 올바른 선택을 계속하면 목표 상태(goal state)에 도달한다.



- 절차
  - 상태 공간 트리에 깊이 우선 탐색을 실시
  - 각 노드가 유망한지 점검
  - 유망하지 않으면 그 노드의 부모 노드로 돌아가서 탐색을 계속



- DFS와의 차이
  - 가지치기(Plunning): 깊이 우선 탐색은 모든 경로를 추적하지만 백트래킹은 어떤 노드에서 출발하는 경로가 해결책으로 이어질 것 같지 않으면 그 경로를 따라가지 않음으로서 시도 횟수를 줄인다.
  - 백트래킹 알고리즘을 적용하면 일반적으로 경우의 수가 줄지만 이 역시 최악의 경우에는 여전히 지수함수 시간을 요하므로 처리 불가능



- 가지치기
  - 루트 노드에서 리프 노드까지의 경로는 해답 후보가 되는데 깊이 우선 탐색을 하여 그 해답후보 중에서 답을 찾을 수 있다. 그러나 이 방법을 사용하면 해답이 될 가능성이 전혀 없는 노드의 후손 노드들도 모두 검색해야 하므로 비효율적이다.
  - 모든 후보를 검사하지 않고 어떤 노드의 유망성을 점검한 후에 유망하지 않다고 결정되면 그 노드의 부모 노드로 되돌아가(백트래킹) 다음 자식 노드로 감
  - 유망하다는 것은 노드를 방문했을 때 그 노드를 포함한 경로가 해답이 될 수 있다는 것이다.
  - 가지치기는 유망하지 않은 노드가 포함되는 경로를 더 이상 고려하지 않는 것이다.



- 문제 유형
  - 모든 부분집합 구하기
  - 조합 구하기: 전체 집합에서 몇 개만 선택
    - 모든 부분집합을 구하는 문제 유형에 포함된다고도 볼 수 있다.
    - 예를 들어 <sub>6</sub>C<sub>3</sub>은 요소의 개수가 3인 부분집합을 구하는 것이다.
  - 순열 구하기: 집합의 순서를 변경



- DFS,BFS,백트래킹 문제를 풀 때에는 내가 생각하는 그래프, 혹은 상태공간 트리를 그려보고 최적해를 탐색하는 과정을 생각해 보면 된다.



# 문제 풀면서 알게 된 것들

- b_2667_단지 번호 붙이기

  - 리스트를 기준으로 반복문이 수행될 때, 리스트의 길이를 기준으로 수행될 때와 리스트로 반복문이 수행될 때 차이가 존재한다.

    ```python
    #길이를 기준으로 수행 되는 경우
    arr = [1]
    for i in range(len(arr)):
    	arr.append(i)
    	print("i")
    #위의 경우 반복문에 진입할 때의 arr의 길이를 기준으로 1번만 수행된다.
        
    
    #리스트를 기준으로 수행 되는 경우
    arr = [1]
    for i in arr:
    	arr.append(i)
    	print(i)
    #반면 위의 경우 arr에 계속 append가 되면서 반복문이 무한히 돌게 된다.
    ```




- BFS에서의 return

  - 함수를 정의해서 BFS를 풀 경우 `return`을 주의하라

  ```python
  import sys
  sys.setrecursionlimit(10 ** 6)
  
  dr = [-1, 1, 0, 0]
  dc = [0, 0, -1, 1]
  
  def dfs(r,c,k):
      for i in range(4):
          nr=r+dr[i]
          nc=c+dc[i]
          if nr>=N or nr<0 or nc >=N or nc<0:
              continue
          if maps[nr][nc] == 0:
              maps[r][c] = k
          if maps[nr][nc]==1:
              maps[nr][nc]="L"
              dfs(nr,nc,k)
  
  def bfs(k):
      global Q, Min
      while Q:
          NQ=[]
          for r,c in Q:
              if visited[r][c]>Min:
                  break         #break가 아닌 return을 써서 틀림 return할 경우 Q에 요소가 남아있는 상태로 다음 bfs로 넘어가게 된다.
              for i in range(4):
                  nr=r+dr[i]
                  nc=c+dc[i]
                  if nr>=N or nr<0 or nc>=N or nc<0:
                      continue
                  if maps[nr][nc] !=k and maps[nr][nc] in tk:
                      if Min>visited[r][c]:
                          Min=visited[r][c]
                          break
                  if maps[nr][nc]==0 and visited[nr][nc]==0:
                      NQ.append([nr,nc])
                      visited[nr][nc]=visited[r][c]+1
          Q=NQ
  
  
  N = int(input())
  maps=[list(map(int, input().split())) for _ in range(N)]
  Min= 987654321
  
  k=1
  tk=[]
  for i in range(N):
      for j in range(N):
          if maps[i][j]==1:
              k+=1
              tk.append(k)
              maps[i][j]="L"
              dfs(i,j,k)
  
  Q = []
  for i in range(N):
      for j in range(N):
          if maps[i][j] in tk:
              visited = [[0] * N for _ in range(N)]
              a = maps[i][j]
              Q.append([i,j])
              visited[i][j] = 1
              bfs(a)
  
  print(Min-1)
  ```







# 팁

- 파이썬에서 음수의 나눗셈
  - `//`연산자는 소수점 아래에 대해서는 `floor()`처리된다.
    - 두 정수 사이의 값일 경우 더 작은 값이 결과값이 된다.
  - `%`연산자의 결과값의 부호는 나누는 수(젯수)의 부호를 따른다.
    - a/b의 몫 q, 나머지 r이라고 할 때, `a=b*q+r`, `0<=|r|<b`가 항상 성립하도록 결과값을 리턴하도록 설계되어 있다.
  
  ```python
  a,b = -3,2
  print(a//b)
  print(int(a/b))
  if a<0:
  	print(-(abs(a)//b))
  
  #a//b의 경우 결과값이 다르게 나온다. 따라서 파이썬에서 음수의 나눗셈을 할 경우 다른 두 경우와 같이 해주는 것이 좋다.
  out
  -2
  -1
  -1
  ```





- 이차배열 형성할 때 주의 점

  ```python
  arr = [[0]*3]*3 #이와 같이 생성하면 안되는데 그 이유는
  arr[0][0] = 1
  arr[0][1] = 2
  arr[0][2] = 3
  print(arr)
  
  out
  [[1,2,3],[1,2,3],[1,2,3]] #이처럼 출력된다.
  #즉 원본 을 그대로 복사해서 적용되기에 이처럼 이차배열을 설정해선 안된다.
  
  따라서 아래와 같이 생성해야 한다.
  arr = [[0]*3 for _ in range(3)]
  ```





- 배열의 인덱스 설정을 위해 범위를 설정할 때(e.g. 미로 문제에서 범위를 벗어날 경우의 처리) 인덱스를 활용한 조건을 함께 써준다면, 반드시 범위 관련 설정을 먼저 써야 한다.

  ```python
  if nr>=N or nr<0 or nc>=N or nc<0 and visited[nr][nc]==0:
  
  #만일 위와 같은 코드를 아래와 같이 쓰면 인덱스 에러가 날 수 있다.
  
  if visited[nr][nc]==0 and nr>=N or nr<0 or nc>=N or nc<0:
      
  and는 앞에서부터 참거짓을 판별하여 앞의 조건이 거짓이면 뒤의 조건은 판별하지 않고 False를 반환한다.
  만일 nr이나 nc가 범위를 벗어난 값일 경우 첫 번째 코드처럼 쓰면 뒤의 visited[nr][nc]==0은 처리되지 않고 넘어간다. 그러나 두 번째 코드처럼 쓰면 우선 앞의 if visited[nr][nc]==0를 먼저 판별하는데 만일 nr이나 nc가 범위를 벗어난 값이었다면 인덱스 에러가 발생하게 된다.
  ```

  



- list 기반 loop에서 list를 수정하는 방법

  - 아래와 같이 list를 기반으로 loop를 수행할 때가 있다.

  ```python
  lst = [1,2,3,4,5]
  for i in lst:
      print(i)
  
  # 또는
  for i in range(len(lst)):
      print(i)
  ```

  - 이 때 반복 중인 list를 수정하는 것은 위험할 수 있다.
    - 예를 들어 아래와 같은 경우 out of index error가 발생한다.

  ```python
  lst = [1,2,3,4,5]
  
  cnt = 0
  for i in range(len(lst)):
      if i<4:
          lst.remove(lst[i])
      cnt+=1
  ```

  - 이럴 때는 for문 보다는 while문을 사용하는 것이 좋다.
    - 조건에 부합하지 않았을 때만 index를 증가시키고, 조건에 부합할 경우 index를 유지하는 방식을 사용한다.

  ```python
  lst = [1,2,3,4,5]
  
  i = 0
  cnt = 0
  while i != len(lst):
      if cnt<4:
          lst.remove(lst[i])
      else:
          i+=1
      cnt+=1
  ```




- deepcopy

  - Python에서는 `copy` 모듈의 `deepcopy` 함수와 slicing을 통해 깊은 복사가 가능하다.
    - 주의할 점은 slicing의 경우 객체 내부의 객체까지는 복제가 되지 않는다는 점이다.

  - deepcopy 함수는 속도가 느리다.
    - deepcopy를 사용하여 복사하는 것 보다 json의 `dumps`, `loads`를 사용하는 것이 더 빠르다.

  ```python
  from json import dumps, loads
  from copy import deepcopy
  import time
  
  orig_list = [[i for i in range(10)] for i in range(1000000)]
  
  deep_copy_start = time.time()
  copied_list_via_deepcopy = deepcopy(orig_list)
  print(time.time()-deep_copy_start)						# 7.03
  
  slicing_start = time.time()
  copied_list_via_slicing = orig_list[:]
  print(time.time()-slicing_start)						# 0.01
  
  dumps_and_loads_start = time.time()
  copied_list_via_json = dumps(orig_list)
  copied_list_via_json = loads(copied_list_via_json)
  print(time.time()-dumps_and_loads_start)				# 2.78
  
  orig_list[1][0] = 8
  print(copied_list_via_deepcopy[1][0])					# 0
  print(copied_list_via_slicing[1][0])					# 8
  print(copied_list_via_json[1][0])						# 0
  ```

  
