- 리밸런싱(rebalancing)
  - 컨슈머 그룹 내의 컨슈머에 할당된 파티션이 재할당 되는 것.
    - 리밸런싱은 가용성을 높여 안정적인 운영을 도와주는 유용한 기능이지만 자주 일어나서는 안된다.
    - 리밸러시이 발생할 때 파티션을 재할당 하는 과정에서 해당 컨슈머 그룹 내의 컨슈머들이 토픽의 데이터를 읽을 수 없기 때문이다.
  - 리밸런싱은 크게 두 가지 상황에서 일어난다.
    - 컨슈머가 추가될 경우.
    - 컨슈머 그룹 내의 컨슈머들 중 일부 컨슈머에 장애가 발생하면, 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에 재할당 된다.

  - 그룹 조정자
    - 컨슈머 그룹에 컨슈머가 추가되고 삭제될 때를 감지하여 리밸런싱을 발동시키는 역할을 한다.
    - 카프카 브로커 중 한 대가 그룹 조정자의 역할을 수행한다.



- 커밋과 오프셋
  - 컨슈머는 카프카 브로커가 데이터를 어디까지 가져갔는지 커밋을 통해 기록한다.
    - 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지를 브로커 내부에서 사용되는 내부 토픽(`__consumer_offsets`)에 기록한다.
    - 컨슈머 동작 이슈가 발생하여 `__consumer_offsets`에 어느 레코드까지 읽어갔는지 오프셋 커밋이 기록되지 못했다면 데이터 처리의 중복이 발생할 수 있다.
    - 따라서 데이터 처리의 중복이 발생되지 않게 하기 위해서는 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리 했는지 검증해야 한다.
  - 자동 커밋(비명시 오프셋 커밋)
    - 기본 옵션은 `poll()`(파티션에서 메시지를 가져오는 메서드)이 수행될 때 일정 간격마다 오프셋을 커밋하도록 설정되어 있다.
    - 이렇게 일정 간격마다 자동으로 커밋되는 것을 비명시 오프셋 커밋이라 한다.
    - 비명시 오프셋 커밋은 편리하지만 리밸런싱 또는 컨슈머 강제 종료 발생 시 컨슈머가 처리하는 데이터가 중복 또는 유실될 수 있는 가능성이 있다.
    - 따라서 데이터 중복이나 유실을 허용하지 않는 서비스라면 비명시 오프셋 커밋을 사용해서는 안된다.
  - 수동 커밋(명시 오프셋 커밋)
    - 명시적으로 오프셋을 커밋하려면 `poll()` 메서드 호출 이후에 데이터의 처리가 완료 된 후 `commit()`메서드를 호출하면 된다.
    - `commit()` 메서드는 브로커에 커밋 요청을 하고 커밋이 정상적으로 처리 되었는지 응답하기까지 기다리는데, 이는 컨슈머의 처리량에 영향을 미친다.
    - 기존에는 데이터 처리만 했으면 됐는데, 이제는 데이터 처리 + 커밋 요청 및 응답 대기까지 해야 하기 때문이다.
    - 이를 해결하기 위해 비동기적으로 커밋을 할 수도 있지만, 커밋 요청이 실패했을 경우 현재 처리 중인 데이터의 순서를 보장하지 않으며 데이터의 중복 처리가 발생할 수 있다.



- 컨슈머 쥬요 옵션
  - `bootstrap.servers`
    - `브로커의 호스트 이름:포트`를 1개 이상 작성한다.
    - 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데 이슈가 없도록 설정 가능하다.
  - `key.deserializer`
    - 레코드의 메시지 키를 역직렬화하는 클래스를 지정한다.
  - `key.deserializer`
    - 레코드의 메시지 값을 역직렬화 하는 클래스를 지정한다.
  - `group.id`
    - 컨슈머 그룹 아이디를 지정한다.
    - `subscribe()` 메서드로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야 한다.
  - `auto.offset.reset`
    - 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택한다.
    - 이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다.
    - `latest`: 가장 최근에 넣은 오프셋부터 읽는다.
    - `earliest`: 가장 오래전에 넣은 오프셋부터 읽는다.
    - `none`: 컨슈머 그룹이 커밋한 기록이 있는지 찾아보고 커밋 기록이 없으면 오류를 반환하고, 있으면 기존 커밋 기록 이후 오프셋부터 읽기 시작한다.
  - `enable.auto.commit`
    - 자동 커밋(비명시적 오프셋 커밋)으로 할 지 수동 커밋(명시적 오프셋 커밋)으로 할지를 설정한다.
  - `auto.commit.interval.ms`
    - 자동 커밋일 경우 오프셋 커밋 간격을 지정한다.
    - `poll()` 메서드가 호출될 때, 이 옵션에 설정해준 기간이 지난 레코드들을 커밋한다.
  - `max.poll.records`
    - `poll()`메서드를 통해 반환되는 레코드의 개수를 지정한다.
  - `session.timeout.ms`
    - 컨슈머가 브로커와 연결이 끊기는 최대 시간을 설정한다.
    - 이 시간 내에 하트비트를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱을 시작한다.
    - 보통 하트비트 시간 간격의 3배로 설정한다.
  - `heatbeat.interval.ms`
    - 하트비트를 전송하는 시간 간격이다.
  - `max.poll.interval.ms`
    - `poll()` 메서드를 호출하는 간격의 최대 시간을 지정한다.
    - `poll()` 메서드를 호출한 이후에 여기서 설정해준 시간 내에 `poll()` 메서드가 다시 실행되지 않으면, 컨슈머에 이상이 생긴 것으로 판단하고 리밸런싱을 시작한다.
  - `isolation.level`
    - 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용한다.
    - `read_commited`, `read_uncommited`로 설정할 수 있다.
    - `read_commited`로 설정하면 커밋이 완료된 레코드만 읽는다.
    - `read_uncommited`로 설정하면 커밋 여부와 관계 없이 파티션에 있는 모든 레코드를 읽는다.



- 컨슈머의 안전한 종료
  - 정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할때까지 컨슈머 그룹에 남게 된다.
    - 이로 인해 해당 컨슈머에 할당된 파티션의 데이터는 소모되지 못하고 컨슈머 렉이 늘어나게 된다.
    - 컨슈머 렉이 늘어나면 데이터 처리 지연 현상이 발생한다.
  - 따라서 각 카프카 라이브러리들이 지원하는 컨슈머 종료 관련 메서드를 통해 컨슈머를 안전하게 종료해줘야 한다.





## 카프카 확장

- 카프카 스트림즈

  - 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리.
    - 카프카에서 공식적으로 지원하는 라이브러리다.
  - JMV에서만 실행이 가능하다.
    - Python에도 아래와 같은 라이브러리가 존재하기는 하지만 현재 관리가 되지 않고 있다.
    - [robinhood/faust](https://github.com/robinhood/faust)
    - [wintincode/winton-kafka-streams](https://github.com/wintoncode/winton-kafka-streams)

  - 필요할 경우 추후 추가
    - 아파치 카프카 애플리케이션 프로그래밍(p.117)



- 카프카 커넥트
  - 프로듀서, 컨슈머 애플리케이션을 만드는 것은 좋은 방법이지만 반복적인 파이프라인 생성 작업이 있을 때는 매번 프로듀서, 컨슈머 애플리케이션을 개발하고 배포, 운영하는 것이 비효율적일 수 있다.
  - 커넥트는 특정 작업 형태를 템플릿으로 만들어 놓은 커넥터를 실행함으로써 반복 작업을 줄일 수 있다.
  - 필요할 경우 추후 추가
    - 아파치 카프카 애플리케이션 프로그래밍(p.153)



- 카프카 미러메이커2
  - 서로 다른 두 개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션
  - 필요할 경우 추후 추가
    - 아파치 카프카 애플리케이션 프로그래밍(p.188)
